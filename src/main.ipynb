{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtype</th>\n",
       "      <th>valid_count</th>\n",
       "      <th>nan_count</th>\n",
       "      <th>unique_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit</th>\n",
       "      <td>category</td>\n",
       "      <td>11898</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_name</th>\n",
       "      <td>object</td>\n",
       "      <td>11898</td>\n",
       "      <td>0</td>\n",
       "      <td>3451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand</th>\n",
       "      <td>object</td>\n",
       "      <td>11868</td>\n",
       "      <td>30</td>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>object</td>\n",
       "      <td>11898</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size</th>\n",
       "      <td>object</td>\n",
       "      <td>11898</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size_main</th>\n",
       "      <td>object</td>\n",
       "      <td>10981</td>\n",
       "      <td>917</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size_suffix</th>\n",
       "      <td>object</td>\n",
       "      <td>1621</td>\n",
       "      <td>10277</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size_scheme</th>\n",
       "      <td>object</td>\n",
       "      <td>11861</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>float64</td>\n",
       "      <td>11898</td>\n",
       "      <td>0</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rented_for</th>\n",
       "      <td>object</td>\n",
       "      <td>10476</td>\n",
       "      <td>1422</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usually_wear</th>\n",
       "      <td>float64</td>\n",
       "      <td>11848</td>\n",
       "      <td>50</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>float64</td>\n",
       "      <td>11553</td>\n",
       "      <td>345</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>height</th>\n",
       "      <td>float64</td>\n",
       "      <td>7869</td>\n",
       "      <td>4029</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>float64</td>\n",
       "      <td>9317</td>\n",
       "      <td>2581</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body_type</th>\n",
       "      <td>object</td>\n",
       "      <td>7931</td>\n",
       "      <td>3967</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bust_size</th>\n",
       "      <td>float64</td>\n",
       "      <td>9782</td>\n",
       "      <td>2116</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cup_size</th>\n",
       "      <td>category</td>\n",
       "      <td>9782</td>\n",
       "      <td>2116</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dtype  valid_count  nan_count  unique_count\n",
       "fit           category        11898          0             3\n",
       "item_name       object        11898          0          3451\n",
       "brand           object        11868         30           466\n",
       "category        object        11898          0            68\n",
       "size            object        11898          0           124\n",
       "size_main       object        10981        917            59\n",
       "size_suffix     object         1621      10277             5\n",
       "size_scheme     object        11861         37             4\n",
       "price          float64        11898          0           443\n",
       "rented_for      object        10476       1422             8\n",
       "usually_wear   float64        11848         50            24\n",
       "age            float64        11553        345            61\n",
       "height         float64         7869       4029            21\n",
       "weight         float64         9317       2581           147\n",
       "body_type       object         7931       3967             7\n",
       "bust_size      float64         9782       2116            11\n",
       "cup_size      category         9782       2116            13"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "mpl.rcParams['font.family'] = ['serif']\n",
    "mpl.rcParams['font.serif'] = ['Times New Roman']\n",
    "mpl.rcParams['mathtext.fontset'] = 'cm'\n",
    "\n",
    "import utils\n",
    "import preprocess\n",
    "\n",
    "importlib.reload(utils)\n",
    "importlib.reload(preprocess)\n",
    "\n",
    "from utils import fetch_train_data, describe_data, evaluate_model, train_test_split\n",
    "from preprocess import *\n",
    "\n",
    "# df = fetch_train_data(path='../data/train_data_all_filled.json')\n",
    "df = fetch_train_data()\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "\n",
    "prep = Preprocessor()\n",
    "train_df = prep.cleanse(train_df, is_train=True)\n",
    "train_df.dropna(subset=['fit'], inplace=True)\n",
    "\n",
    "test_df = prep.cleanse(test_df)\n",
    "test_df.dropna(subset=['fit'], inplace=True)\n",
    "\n",
    "describe_data(test_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'preprocess.DropColumns'>\n",
      "<class 'preprocess.OneHotEncoder'>\n",
      "<class 'preprocess.OrdinalEncoder'>\n",
      "<class 'preprocess.StandardScaler'>\n",
      "<class 'preprocess.MinMaxScaler'>\n",
      "<class 'preprocess.SelectOutputColumns'>\n",
      "<class 'preprocess.MeanImputer'>\n",
      "<class 'preprocess.MedianImputer'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep.pipeline = [\n",
    "    DropColumns([\n",
    "        'user_name', 'review', 'review_summary', 'rating', 'size', 'item_name'\n",
    "    ]),\n",
    "    OneHotEncoder([\n",
    "        'size_scheme', 'size_main', 'size_suffix', 'brand', 'category',\n",
    "        'rented_for', 'body_type'\n",
    "    ],\n",
    "                  name='one_hot'),\n",
    "    OrdinalEncoder(['fit', 'cup_size']),\n",
    "    StandardScaler(['age', 'weight', 'height', 'bust_size', 'cup_size']),\n",
    "    MinMaxScaler(['price', 'usually_wear']),\n",
    "    SelectOutputColumns(\n",
    "        'one_hot'\n",
    "    ),  # append the output of 'one_hot' to the input of the next transformer\n",
    "    MeanImputer(['age', 'weight', 'height', 'bust_size', 'cup_size']),\n",
    "    MedianImputer(['usually_wear']),\n",
    "]\n",
    "\n",
    "train_df_prep, test_df_prep = train_df.copy(), test_df.copy()\n",
    "train_df_prep = prep.fit_transform(train_df_prep)\n",
    "test_df_prep = prep.transform(test_df_prep)\n",
    "\n",
    "describe_data(train_df_prep)['nan_count'].sum()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas_profiling import ProfileReport\n",
    "\n",
    "# profile = ProfileReport(test_df, minimal=True)\n",
    "# profile.to_notebook_iframe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto ML with PyCaret (Incorrect Metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_523c7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_523c7_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_523c7_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_523c7_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_523c7_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_523c7_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_523c7_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_523c7_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_523c7_row1_col1\" class=\"data row1 col1\" >fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_523c7_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_523c7_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_523c7_row2_col1\" class=\"data row2 col1\" >Multiclass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_523c7_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_523c7_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_523c7_row3_col1\" class=\"data row3 col1\" >(59827, 649)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_523c7_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_523c7_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_523c7_row4_col1\" class=\"data row4 col1\" >(59827, 649)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_523c7_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_523c7_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_523c7_row5_col1\" class=\"data row5 col1\" >(47929, 649)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_523c7_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_523c7_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_523c7_row6_col1\" class=\"data row6 col1\" >(11898, 649)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_523c7_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_523c7_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_523c7_row7_col1\" class=\"data row7 col1\" >648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x28784dc00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pycaret.classification import *\n",
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    setup(\n",
    "        data=train_df_prep,\n",
    "        test_data=test_df_prep,\n",
    "        target='fit',\n",
    "        preprocess=False,\n",
    "        session_id=0,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3513d th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_3513d_row0_col0, #T_3513d_row0_col2, #T_3513d_row0_col4, #T_3513d_row0_col5, #T_3513d_row0_col6, #T_3513d_row0_col7, #T_3513d_row1_col0, #T_3513d_row1_col1, #T_3513d_row1_col2, #T_3513d_row1_col3, #T_3513d_row1_col4, #T_3513d_row1_col5, #T_3513d_row1_col6, #T_3513d_row1_col7, #T_3513d_row2_col0, #T_3513d_row2_col1, #T_3513d_row2_col3, #T_3513d_row2_col4, #T_3513d_row2_col5, #T_3513d_row2_col6, #T_3513d_row2_col7, #T_3513d_row3_col0, #T_3513d_row3_col1, #T_3513d_row3_col2, #T_3513d_row3_col3, #T_3513d_row3_col4, #T_3513d_row4_col0, #T_3513d_row4_col1, #T_3513d_row4_col2, #T_3513d_row4_col3, #T_3513d_row4_col4, #T_3513d_row4_col5, #T_3513d_row4_col6, #T_3513d_row4_col7, #T_3513d_row5_col0, #T_3513d_row5_col1, #T_3513d_row5_col2, #T_3513d_row5_col3, #T_3513d_row5_col5, #T_3513d_row5_col6, #T_3513d_row5_col7, #T_3513d_row6_col0, #T_3513d_row6_col1, #T_3513d_row6_col2, #T_3513d_row6_col3, #T_3513d_row6_col4, #T_3513d_row6_col5, #T_3513d_row6_col6, #T_3513d_row6_col7, #T_3513d_row7_col0, #T_3513d_row7_col1, #T_3513d_row7_col2, #T_3513d_row7_col3, #T_3513d_row7_col4, #T_3513d_row7_col5, #T_3513d_row7_col6, #T_3513d_row7_col7, #T_3513d_row8_col0, #T_3513d_row8_col1, #T_3513d_row8_col2, #T_3513d_row8_col3, #T_3513d_row8_col4, #T_3513d_row8_col5, #T_3513d_row8_col6, #T_3513d_row8_col7, #T_3513d_row9_col0, #T_3513d_row9_col1, #T_3513d_row9_col2, #T_3513d_row9_col3, #T_3513d_row9_col4, #T_3513d_row9_col5, #T_3513d_row9_col6, #T_3513d_row9_col7, #T_3513d_row10_col0, #T_3513d_row10_col1, #T_3513d_row10_col2, #T_3513d_row10_col3, #T_3513d_row10_col4, #T_3513d_row10_col5, #T_3513d_row10_col6, #T_3513d_row10_col7, #T_3513d_row11_col0, #T_3513d_row11_col1, #T_3513d_row11_col2, #T_3513d_row11_col3, #T_3513d_row11_col4, #T_3513d_row11_col5, #T_3513d_row11_col6, #T_3513d_row11_col7, #T_3513d_row12_col0, #T_3513d_row12_col1, #T_3513d_row12_col2, #T_3513d_row12_col3, #T_3513d_row12_col4, #T_3513d_row12_col5, #T_3513d_row12_col6, #T_3513d_row12_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_3513d_row0_col1, #T_3513d_row0_col3, #T_3513d_row2_col2, #T_3513d_row3_col5, #T_3513d_row3_col6, #T_3513d_row3_col7, #T_3513d_row5_col4 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_3513d_row0_col8, #T_3513d_row1_col8, #T_3513d_row2_col8, #T_3513d_row3_col8, #T_3513d_row4_col8, #T_3513d_row5_col8, #T_3513d_row6_col8, #T_3513d_row7_col8, #T_3513d_row9_col8, #T_3513d_row10_col8, #T_3513d_row11_col8, #T_3513d_row12_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_3513d_row8_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3513d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3513d_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_3513d_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_3513d_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_3513d_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_3513d_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_3513d_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_3513d_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_3513d_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_3513d_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3513d_level0_row0\" class=\"row_heading level0 row0\" >lr</th>\n",
       "      <td id=\"T_3513d_row0_col0\" class=\"data row0 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_3513d_row0_col1\" class=\"data row0 col1\" >0.6981</td>\n",
       "      <td id=\"T_3513d_row0_col2\" class=\"data row0 col2\" >0.6676</td>\n",
       "      <td id=\"T_3513d_row0_col3\" class=\"data row0 col3\" >0.6981</td>\n",
       "      <td id=\"T_3513d_row0_col4\" class=\"data row0 col4\" >0.6577</td>\n",
       "      <td id=\"T_3513d_row0_col5\" class=\"data row0 col5\" >0.6252</td>\n",
       "      <td id=\"T_3513d_row0_col6\" class=\"data row0 col6\" >0.1582</td>\n",
       "      <td id=\"T_3513d_row0_col7\" class=\"data row0 col7\" >0.2125</td>\n",
       "      <td id=\"T_3513d_row0_col8\" class=\"data row0 col8\" >13.6830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3513d_level0_row1\" class=\"row_heading level0 row1\" >ridge</th>\n",
       "      <td id=\"T_3513d_row1_col0\" class=\"data row1 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_3513d_row1_col1\" class=\"data row1 col1\" >0.6965</td>\n",
       "      <td id=\"T_3513d_row1_col2\" class=\"data row1 col2\" >0.0000</td>\n",
       "      <td id=\"T_3513d_row1_col3\" class=\"data row1 col3\" >0.6965</td>\n",
       "      <td id=\"T_3513d_row1_col4\" class=\"data row1 col4\" >0.6552</td>\n",
       "      <td id=\"T_3513d_row1_col5\" class=\"data row1 col5\" >0.6188</td>\n",
       "      <td id=\"T_3513d_row1_col6\" class=\"data row1 col6\" >0.1442</td>\n",
       "      <td id=\"T_3513d_row1_col7\" class=\"data row1 col7\" >0.2011</td>\n",
       "      <td id=\"T_3513d_row1_col8\" class=\"data row1 col8\" >0.2600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3513d_level0_row2\" class=\"row_heading level0 row2\" >rf</th>\n",
       "      <td id=\"T_3513d_row2_col0\" class=\"data row2 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_3513d_row2_col1\" class=\"data row2 col1\" >0.6930</td>\n",
       "      <td id=\"T_3513d_row2_col2\" class=\"data row2 col2\" >0.6697</td>\n",
       "      <td id=\"T_3513d_row2_col3\" class=\"data row2 col3\" >0.6930</td>\n",
       "      <td id=\"T_3513d_row2_col4\" class=\"data row2 col4\" >0.6711</td>\n",
       "      <td id=\"T_3513d_row2_col5\" class=\"data row2 col5\" >0.5976</td>\n",
       "      <td id=\"T_3513d_row2_col6\" class=\"data row2 col6\" >0.0894</td>\n",
       "      <td id=\"T_3513d_row2_col7\" class=\"data row2 col7\" >0.1595</td>\n",
       "      <td id=\"T_3513d_row2_col8\" class=\"data row2 col8\" >7.1890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3513d_level0_row3\" class=\"row_heading level0 row3\" >lda</th>\n",
       "      <td id=\"T_3513d_row3_col0\" class=\"data row3 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_3513d_row3_col1\" class=\"data row3 col1\" >0.6921</td>\n",
       "      <td id=\"T_3513d_row3_col2\" class=\"data row3 col2\" >0.6654</td>\n",
       "      <td id=\"T_3513d_row3_col3\" class=\"data row3 col3\" >0.6921</td>\n",
       "      <td id=\"T_3513d_row3_col4\" class=\"data row3 col4\" >0.6463</td>\n",
       "      <td id=\"T_3513d_row3_col5\" class=\"data row3 col5\" >0.6377</td>\n",
       "      <td id=\"T_3513d_row3_col6\" class=\"data row3 col6\" >0.1922</td>\n",
       "      <td id=\"T_3513d_row3_col7\" class=\"data row3 col7\" >0.2245</td>\n",
       "      <td id=\"T_3513d_row3_col8\" class=\"data row3 col8\" >3.9180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3513d_level0_row4\" class=\"row_heading level0 row4\" >svm</th>\n",
       "      <td id=\"T_3513d_row4_col0\" class=\"data row4 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_3513d_row4_col1\" class=\"data row4 col1\" >0.6920</td>\n",
       "      <td id=\"T_3513d_row4_col2\" class=\"data row4 col2\" >0.0000</td>\n",
       "      <td id=\"T_3513d_row4_col3\" class=\"data row4 col3\" >0.6920</td>\n",
       "      <td id=\"T_3513d_row4_col4\" class=\"data row4 col4\" >0.6429</td>\n",
       "      <td id=\"T_3513d_row4_col5\" class=\"data row4 col5\" >0.6032</td>\n",
       "      <td id=\"T_3513d_row4_col6\" class=\"data row4 col6\" >0.1111</td>\n",
       "      <td id=\"T_3513d_row4_col7\" class=\"data row4 col7\" >0.1712</td>\n",
       "      <td id=\"T_3513d_row4_col8\" class=\"data row4 col8\" >1.7510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3513d_level0_row5\" class=\"row_heading level0 row5\" >gbc</th>\n",
       "      <td id=\"T_3513d_row5_col0\" class=\"data row5 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_3513d_row5_col1\" class=\"data row5 col1\" >0.6886</td>\n",
       "      <td id=\"T_3513d_row5_col2\" class=\"data row5 col2\" >0.6495</td>\n",
       "      <td id=\"T_3513d_row5_col3\" class=\"data row5 col3\" >0.6886</td>\n",
       "      <td id=\"T_3513d_row5_col4\" class=\"data row5 col4\" >0.7034</td>\n",
       "      <td id=\"T_3513d_row5_col5\" class=\"data row5 col5\" >0.5724</td>\n",
       "      <td id=\"T_3513d_row5_col6\" class=\"data row5 col6\" >0.0373</td>\n",
       "      <td id=\"T_3513d_row5_col7\" class=\"data row5 col7\" >0.1124</td>\n",
       "      <td id=\"T_3513d_row5_col8\" class=\"data row5 col8\" >27.3690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3513d_level0_row6\" class=\"row_heading level0 row6\" >ada</th>\n",
       "      <td id=\"T_3513d_row6_col0\" class=\"data row6 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_3513d_row6_col1\" class=\"data row6 col1\" >0.6854</td>\n",
       "      <td id=\"T_3513d_row6_col2\" class=\"data row6 col2\" >0.6090</td>\n",
       "      <td id=\"T_3513d_row6_col3\" class=\"data row6 col3\" >0.6854</td>\n",
       "      <td id=\"T_3513d_row6_col4\" class=\"data row6 col4\" >0.6519</td>\n",
       "      <td id=\"T_3513d_row6_col5\" class=\"data row6 col5\" >0.5695</td>\n",
       "      <td id=\"T_3513d_row6_col6\" class=\"data row6 col6\" >0.0305</td>\n",
       "      <td id=\"T_3513d_row6_col7\" class=\"data row6 col7\" >0.0864</td>\n",
       "      <td id=\"T_3513d_row6_col8\" class=\"data row6 col8\" >2.4760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3513d_level0_row7\" class=\"row_heading level0 row7\" >et</th>\n",
       "      <td id=\"T_3513d_row7_col0\" class=\"data row7 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_3513d_row7_col1\" class=\"data row7 col1\" >0.6848</td>\n",
       "      <td id=\"T_3513d_row7_col2\" class=\"data row7 col2\" >0.6618</td>\n",
       "      <td id=\"T_3513d_row7_col3\" class=\"data row7 col3\" >0.6848</td>\n",
       "      <td id=\"T_3513d_row7_col4\" class=\"data row7 col4\" >0.6371</td>\n",
       "      <td id=\"T_3513d_row7_col5\" class=\"data row7 col5\" >0.6284</td>\n",
       "      <td id=\"T_3513d_row7_col6\" class=\"data row7 col6\" >0.1629</td>\n",
       "      <td id=\"T_3513d_row7_col7\" class=\"data row7 col7\" >0.1938</td>\n",
       "      <td id=\"T_3513d_row7_col8\" class=\"data row7 col8\" >10.4240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3513d_level0_row8\" class=\"row_heading level0 row8\" >dummy</th>\n",
       "      <td id=\"T_3513d_row8_col0\" class=\"data row8 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_3513d_row8_col1\" class=\"data row8 col1\" >0.6827</td>\n",
       "      <td id=\"T_3513d_row8_col2\" class=\"data row8 col2\" >0.5000</td>\n",
       "      <td id=\"T_3513d_row8_col3\" class=\"data row8 col3\" >0.6827</td>\n",
       "      <td id=\"T_3513d_row8_col4\" class=\"data row8 col4\" >0.4661</td>\n",
       "      <td id=\"T_3513d_row8_col5\" class=\"data row8 col5\" >0.5540</td>\n",
       "      <td id=\"T_3513d_row8_col6\" class=\"data row8 col6\" >0.0000</td>\n",
       "      <td id=\"T_3513d_row8_col7\" class=\"data row8 col7\" >0.0000</td>\n",
       "      <td id=\"T_3513d_row8_col8\" class=\"data row8 col8\" >0.0320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3513d_level0_row9\" class=\"row_heading level0 row9\" >knn</th>\n",
       "      <td id=\"T_3513d_row9_col0\" class=\"data row9 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_3513d_row9_col1\" class=\"data row9 col1\" >0.6407</td>\n",
       "      <td id=\"T_3513d_row9_col2\" class=\"data row9 col2\" >0.5858</td>\n",
       "      <td id=\"T_3513d_row9_col3\" class=\"data row9 col3\" >0.6407</td>\n",
       "      <td id=\"T_3513d_row9_col4\" class=\"data row9 col4\" >0.5806</td>\n",
       "      <td id=\"T_3513d_row9_col5\" class=\"data row9 col5\" >0.5939</td>\n",
       "      <td id=\"T_3513d_row9_col6\" class=\"data row9 col6\" >0.1053</td>\n",
       "      <td id=\"T_3513d_row9_col7\" class=\"data row9 col7\" >0.1150</td>\n",
       "      <td id=\"T_3513d_row9_col8\" class=\"data row9 col8\" >13.8770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3513d_level0_row10\" class=\"row_heading level0 row10\" >dt</th>\n",
       "      <td id=\"T_3513d_row10_col0\" class=\"data row10 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_3513d_row10_col1\" class=\"data row10 col1\" >0.5832</td>\n",
       "      <td id=\"T_3513d_row10_col2\" class=\"data row10 col2\" >0.5569</td>\n",
       "      <td id=\"T_3513d_row10_col3\" class=\"data row10 col3\" >0.5832</td>\n",
       "      <td id=\"T_3513d_row10_col4\" class=\"data row10 col4\" >0.5761</td>\n",
       "      <td id=\"T_3513d_row10_col5\" class=\"data row10 col5\" >0.5795</td>\n",
       "      <td id=\"T_3513d_row10_col6\" class=\"data row10 col6\" >0.1223</td>\n",
       "      <td id=\"T_3513d_row10_col7\" class=\"data row10 col7\" >0.1224</td>\n",
       "      <td id=\"T_3513d_row10_col8\" class=\"data row10 col8\" >1.3060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3513d_level0_row11\" class=\"row_heading level0 row11\" >qda</th>\n",
       "      <td id=\"T_3513d_row11_col0\" class=\"data row11 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_3513d_row11_col1\" class=\"data row11 col1\" >0.2278</td>\n",
       "      <td id=\"T_3513d_row11_col2\" class=\"data row11 col2\" >0.5028</td>\n",
       "      <td id=\"T_3513d_row11_col3\" class=\"data row11 col3\" >0.2278</td>\n",
       "      <td id=\"T_3513d_row11_col4\" class=\"data row11 col4\" >0.5752</td>\n",
       "      <td id=\"T_3513d_row11_col5\" class=\"data row11 col5\" >0.1151</td>\n",
       "      <td id=\"T_3513d_row11_col6\" class=\"data row11 col6\" >0.0055</td>\n",
       "      <td id=\"T_3513d_row11_col7\" class=\"data row11 col7\" >0.0322</td>\n",
       "      <td id=\"T_3513d_row11_col8\" class=\"data row11 col8\" >3.2640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3513d_level0_row12\" class=\"row_heading level0 row12\" >nb</th>\n",
       "      <td id=\"T_3513d_row12_col0\" class=\"data row12 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_3513d_row12_col1\" class=\"data row12 col1\" >0.1983</td>\n",
       "      <td id=\"T_3513d_row12_col2\" class=\"data row12 col2\" >0.5723</td>\n",
       "      <td id=\"T_3513d_row12_col3\" class=\"data row12 col3\" >0.1983</td>\n",
       "      <td id=\"T_3513d_row12_col4\" class=\"data row12 col4\" >0.5902</td>\n",
       "      <td id=\"T_3513d_row12_col5\" class=\"data row12 col5\" >0.1142</td>\n",
       "      <td id=\"T_3513d_row12_col6\" class=\"data row12 col6\" >0.0458</td>\n",
       "      <td id=\"T_3513d_row12_col7\" class=\"data row12 col7\" >0.0954</td>\n",
       "      <td id=\"T_3513d_row12_col8\" class=\"data row12 col8\" >0.6210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x291a78d00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n",
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n",
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n",
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n",
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n",
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n",
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n",
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n",
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n",
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n",
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n",
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n",
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n",
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n",
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n",
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n",
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n",
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n",
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n",
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n"
     ]
    }
   ],
   "source": [
    "best_model = compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_8f4bd\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8f4bd_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_8f4bd_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_8f4bd_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_8f4bd_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_8f4bd_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_8f4bd_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_8f4bd_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8f4bd_level0_row0\" class=\"row_heading level0 row0\" >Test</th>\n",
       "      <td id=\"T_8f4bd_row0_col0\" class=\"data row0 col0\" >0.6988</td>\n",
       "      <td id=\"T_8f4bd_row0_col1\" class=\"data row0 col1\" >0.6784</td>\n",
       "      <td id=\"T_8f4bd_row0_col2\" class=\"data row0 col2\" >0.6988</td>\n",
       "      <td id=\"T_8f4bd_row0_col3\" class=\"data row0 col3\" >0.6519</td>\n",
       "      <td id=\"T_8f4bd_row0_col4\" class=\"data row0 col4\" >0.6261</td>\n",
       "      <td id=\"T_8f4bd_row0_col5\" class=\"data row0 col5\" >0.1541</td>\n",
       "      <td id=\"T_8f4bd_row0_col6\" class=\"data row0 col6\" >0.2057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2b0c19600>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = create_model('lr', cross_validation=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinal Regression with statsmodels (Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "There should not be a constant in the model",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[215], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mstatsmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msm\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mstatsmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmiscmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mordinal_model\u001b[39;00m \u001b[39mimport\u001b[39;00m OrderedModel\n\u001b[0;32m----> 4\u001b[0m model \u001b[39m=\u001b[39m OrderedModel(\n\u001b[1;32m      5\u001b[0m     train_df_prep[\u001b[39m'\u001b[39;49m\u001b[39mfit\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m      6\u001b[0m     train_df_prep\u001b[39m.\u001b[39;49mdrop(\u001b[39m'\u001b[39;49m\u001b[39mfit\u001b[39;49m\u001b[39m'\u001b[39;49m, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m),\n\u001b[1;32m      7\u001b[0m     distr\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mlogit\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m model\u001b[39m.\u001b[39mfit()\n\u001b[1;32m     11\u001b[0m model\u001b[39m.\u001b[39msummary()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/site-packages/statsmodels/miscmodels/ordinal_model.py:155\u001b[0m, in \u001b[0;36mOrderedModel.__init__\u001b[0;34m(self, endog, exog, offset, distr, **kwds)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[39m# Note: Doing the following here would break from_formula\u001b[39;00m\n\u001b[1;32m    152\u001b[0m         \u001b[39m# self.endog = self.endog.argmax(1)\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk_constant \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThere should not be a constant in the model\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    157\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initialize_labels(labels, k_levels\u001b[39m=\u001b[39mk_levels)\n\u001b[1;32m    159\u001b[0m \u001b[39m# adjust df\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: There should not be a constant in the model"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.miscmodels.ordinal_model import OrderedModel\n",
    "\n",
    "model = OrderedModel(\n",
    "    train_df_prep['fit'],\n",
    "    train_df_prep.drop('fit', axis=1),\n",
    "    distr='logit',\n",
    "    \n",
    ")\n",
    "model.fit()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OrdinalClassifier copied from StackOverflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>#small</th>\n",
       "      <th>#true2size</th>\n",
       "      <th>#large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>result</th>\n",
       "      <td>0.618087</td>\n",
       "      <td>0.373367</td>\n",
       "      <td>0.359983</td>\n",
       "      <td>0.354995</td>\n",
       "      <td>0.573198</td>\n",
       "      <td>1055</td>\n",
       "      <td>9868</td>\n",
       "      <td>975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy  precision    recall        f1  f1_weighted  #small  \\\n",
       "result  0.618087   0.373367  0.359983  0.354995     0.573198    1055   \n",
       "\n",
       "        #true2size  #large  \n",
       "result        9868     975  "
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import clone\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "class OrdinalClassifier():\n",
    "\n",
    "    def __init__(self, clf):\n",
    "        self.clf = clf\n",
    "        self.clfs = {}\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.unique_class = np.sort(np.unique(y))\n",
    "        if self.unique_class.shape[0] > 2:\n",
    "            for i in range(self.unique_class.shape[0] - 1):\n",
    "                # for each k - 1 ordinal value we fit a binary classification problem\n",
    "                binary_y = (y > self.unique_class[i]).astype(np.uint8)\n",
    "                clf = clone(self.clf)\n",
    "                clf.fit(X, binary_y)\n",
    "                self.clfs[i] = clf\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        clfs_predict = {k: self.clfs[k].predict_proba(X) for k in self.clfs}\n",
    "        predicted = []\n",
    "        for i, y in enumerate(self.unique_class):\n",
    "            if i == 0:\n",
    "                # V1 = 1 - Pr(y > V1)\n",
    "                predicted.append(1 - clfs_predict[i][:, 1])\n",
    "            elif i in clfs_predict:\n",
    "                # Vi = Pr(y > Vi-1) - Pr(y > Vi)\n",
    "                predicted.append(clfs_predict[i - 1][:, 1] -\n",
    "                                 clfs_predict[i][:, 1])\n",
    "            else:\n",
    "                # Vk = Pr(y > Vk-1)\n",
    "                predicted.append(clfs_predict[i - 1][:, 1])\n",
    "        return np.vstack(predicted).T\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.predict_proba(X), axis=1)\n",
    "\n",
    "\n",
    "model = OrdinalClassifier(LogisticRegression())\n",
    "model.fit(train_df_prep.drop('fit', axis=1), train_df_prep['fit'])\n",
    "y_pred = model.predict(test_df_prep.drop('fit', axis=1))\n",
    "\n",
    "evaluate_model(test_df_prep['fit'], y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Logistic Regression with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>#small</th>\n",
       "      <th>#true2size</th>\n",
       "      <th>#large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>result</th>\n",
       "      <td>0.6059</td>\n",
       "      <td>0.372036</td>\n",
       "      <td>0.361644</td>\n",
       "      <td>0.358883</td>\n",
       "      <td>0.569806</td>\n",
       "      <td>1225</td>\n",
       "      <td>9579</td>\n",
       "      <td>1094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy  precision    recall        f1  f1_weighted  #small  \\\n",
       "result    0.6059   0.372036  0.361644  0.358883     0.569806    1225   \n",
       "\n",
       "        #true2size  #large  \n",
       "result        9579    1094  "
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(train_df_prep.drop('fit', axis=1), train_df_prep['fit'])\n",
    "y_pred = model.predict(test_df_prep.drop('fit', axis=1))\n",
    "\n",
    "evaluate_model(test_df_prep['fit'], y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>#small</th>\n",
       "      <th>#true2size</th>\n",
       "      <th>#large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>result</th>\n",
       "      <td>0.338712</td>\n",
       "      <td>0.338097</td>\n",
       "      <td>0.341459</td>\n",
       "      <td>0.297653</td>\n",
       "      <td>0.379527</td>\n",
       "      <td>3976</td>\n",
       "      <td>3981</td>\n",
       "      <td>3941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy  precision    recall        f1  f1_weighted  #small  \\\n",
       "result  0.338712   0.338097  0.341459  0.297653     0.379527    3976   \n",
       "\n",
       "        #true2size  #large  \n",
       "result        3981    3941  "
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.random.randint(0, 3, size=test_df_prep.shape[0])\n",
    "evaluate_model(test_df_prep['fit'], y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 1.9777\n",
      "Epoch [20/100], Loss: 1.8443\n",
      "Epoch [30/100], Loss: 1.7196\n",
      "Epoch [40/100], Loss: 1.6024\n",
      "Epoch [50/100], Loss: 1.4919\n",
      "Epoch [60/100], Loss: 1.3875\n",
      "Epoch [70/100], Loss: 1.2887\n",
      "Epoch [80/100], Loss: 1.1957\n",
      "Epoch [90/100], Loss: 1.1093\n",
      "Epoch [100/100], Loss: 1.0311\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>#small</th>\n",
       "      <th>#true2size</th>\n",
       "      <th>#large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>result</th>\n",
       "      <td>0.685746</td>\n",
       "      <td>0.228582</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.271194</td>\n",
       "      <td>0.55791</td>\n",
       "      <td>0</td>\n",
       "      <td>11898</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy  precision    recall        f1  f1_weighted  #small  \\\n",
       "result  0.685746   0.228582  0.333333  0.271194      0.55791       0   \n",
       "\n",
       "        #true2size  #large  \n",
       "result       11898       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "input_dim = train_df_prep.drop('fit', axis=1).shape[1]\n",
    "output_dim = 3\n",
    "inputs = torch.tensor(train_df_prep.drop('fit', axis=1).values,\n",
    "                      dtype=torch.float32)\n",
    "labels = torch.tensor(train_df_prep['fit'].values, dtype=torch.long)\n",
    "\n",
    "\n",
    "# Define the model\n",
    "class LogisticRegression(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "num_epochs = 100\n",
    "learning_rate = 0.01\n",
    "lamda = 1\n",
    "\n",
    "# Define the loss function and the optimizer\n",
    "model = LogisticRegression(input_dim, output_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels) + lamda * torch.norm(model.linear.weight)\n",
    "\n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Test the model\n",
    "with torch.no_grad():\n",
    "    predicted = model(\n",
    "        torch.tensor(test_df_prep.drop('fit', axis=1).values,\n",
    "                     dtype=torch.float32))\n",
    "    _, predicted = torch.max(predicted.data, 1)\n",
    "    y_pred = predicted.numpy()\n",
    "\n",
    "evaluate_model(test_df_prep['fit'], y_pred)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression written by ChatGPT (Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (32,) (32,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 56\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[39mreturn\u001b[39;00m probs\u001b[39m.\u001b[39margmax(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     55\u001b[0m model \u001b[39m=\u001b[39m MulticlassLogisticRegression()\n\u001b[0;32m---> 56\u001b[0m model\u001b[39m.\u001b[39;49mfit(inputs, labels)\n\u001b[1;32m     57\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(test_df_prep\u001b[39m.\u001b[39mdrop(\u001b[39m'\u001b[39m\u001b[39mfit\u001b[39m\u001b[39m'\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mvalues)\n\u001b[1;32m     59\u001b[0m evaluate_model(test_df_prep[\u001b[39m'\u001b[39m\u001b[39mfit\u001b[39m\u001b[39m'\u001b[39m], y_pred)\n",
      "Cell \u001b[0;32mIn[8], line 32\u001b[0m, in \u001b[0;36mMulticlassLogisticRegression.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     29\u001b[0m probs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msigmoid(z)\n\u001b[1;32m     31\u001b[0m \u001b[39m# Compute the cost function\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m cost \u001b[39m=\u001b[39m (\u001b[39m-\u001b[39;49my_batch \u001b[39m*\u001b[39;49m np\u001b[39m.\u001b[39;49mlog(probs) \u001b[39m-\u001b[39m\n\u001b[1;32m     33\u001b[0m         (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m y_batch) \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mlog(\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m probs)\n\u001b[1;32m     34\u001b[0m         )\u001b[39m.\u001b[39mmean() \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlambda_ \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39msum(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mw\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[39m# Compute gradients of weight and bias\u001b[39;00m\n\u001b[1;32m     37\u001b[0m dw \u001b[39m=\u001b[39m (X_batch \u001b[39m*\u001b[39m\n\u001b[1;32m     38\u001b[0m       (probs \u001b[39m-\u001b[39m y_batch))\u001b[39m.\u001b[39mmean(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlambda_ \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mw\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (32,) (32,3) "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class MulticlassLogisticRegression:\n",
    "\n",
    "    def __init__(self, batch_size=32, learning_rate=0.01, lambda_=0.01):\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lambda_ = lambda_\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Initialize weight and bias\n",
    "        self.w = np.zeros((X.shape[1], y.max() + 1))\n",
    "        self.b = np.zeros(y.max() + 1)\n",
    "\n",
    "        # Loop over the training data in mini-batches\n",
    "        num_batches = len(X) // self.batch_size\n",
    "        for i in range(num_batches):\n",
    "            start = i * self.batch_size\n",
    "            end = (i + 1) * self.batch_size\n",
    "            X_batch = X[start:end]\n",
    "            y_batch = y[start:end]\n",
    "\n",
    "            # Compute predicted probabilities\n",
    "            z = np.dot(X_batch, self.w) + self.b\n",
    "            probs = self.sigmoid(z)\n",
    "\n",
    "            # Compute the cost function\n",
    "            cost = (-y_batch * np.log(probs) -\n",
    "                    (1 - y_batch) * np.log(1 - probs)\n",
    "                    ).mean() + self.lambda_ * np.sum(self.w**2)\n",
    "\n",
    "            # Compute gradients of weight and bias\n",
    "            dw = (X_batch *\n",
    "                  (probs - y_batch)).mean(axis=0) + 2 * self.lambda_ * self.w\n",
    "            db = (probs - y_batch).mean()\n",
    "\n",
    "            # Update weight and bias\n",
    "            self.w = self.w - self.learning_rate * dw\n",
    "            self.b = self.b - self.learning_rate * db\n",
    "\n",
    "            # Print cost every 10 mini-batches\n",
    "            if i % 10 == 0:\n",
    "                print(f\"Cost at iteration {i}: {cost}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        z = np.dot(X, self.w) + self.b\n",
    "        probs = self.sigmoid(z)\n",
    "        return probs.argmax(axis=1)\n",
    "\n",
    "\n",
    "model = MulticlassLogisticRegression()\n",
    "model.fit(inputs, labels)\n",
    "y_pred = model.predict(test_df_prep.drop('fit', axis=1).values)\n",
    "\n",
    "evaluate_model(test_df_prep['fit'], y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d25da615e19396787fe4ca1ac6e145a6d087d3a93322fbf7b59c4188e44aa5c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
