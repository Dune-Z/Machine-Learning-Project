{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "mpl.rcParams['font.family'] = ['serif']\n",
    "mpl.rcParams['font.serif'] = ['Times New Roman']\n",
    "mpl.rcParams['mathtext.fontset'] = 'cm'\n",
    "\n",
    "import utils\n",
    "import preprocess\n",
    "\n",
    "importlib.reload(utils)\n",
    "importlib.reload(preprocess)\n",
    "\n",
    "from utils import fetch_train_data, describe_data, evaluate_model, train_test_split, random_split_aggr\n",
    "from preprocess import *\n",
    "\n",
    "df = fetch_train_data(path='../data/train_data_all_filled.json')\n",
    "# df = fetch_train_data()\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0)\n",
    "\n",
    "prep = Preprocessor()\n",
    "train_df = prep.cleanse(train_df, is_train=True)\n",
    "# test_df = prep.cleanse(test_df)\n",
    "\n",
    "train_df.dropna(subset=['fit'], inplace=True)\n",
    "# test_df.dropna(subset=['fit'], inplace=True)\n",
    "\n",
    "# describe_data(test_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'preprocess.DropColumns'>\n",
      "<class 'preprocess.HandleSizeMapping'>\n",
      "<class 'preprocess.OrdinalEncoder'>\n",
      "<class 'preprocess.MeanImputer'>\n",
      "<class 'preprocess.ComputeItemVectors'>\n",
      "Optimizing weights and thresholds, round 1\n",
      "Iteration 0: loss = 14.775798797607422\n",
      "Iteration 100: loss = 7.162885665893555\n",
      "Iteration 200: loss = 4.61268949508667\n",
      "Iteration 300: loss = 3.9812064170837402\n",
      "Optimizing item vectors, round 1\n",
      "Iteration 0: loss = 3.976886510848999\n",
      "Iteration 100: loss = 3.9766769409179688\n",
      "Iteration 200: loss = 3.976468086242676\n",
      "Iteration 300: loss = 3.976259708404541\n",
      "Optimizing weights and thresholds, round 2\n",
      "Iteration 0: loss = 3.976257801055908\n",
      "Iteration 100: loss = 3.7788496017456055\n",
      "Iteration 200: loss = 3.60685658454895\n",
      "Iteration 300: loss = 3.4542858600616455\n",
      "Optimizing item vectors, round 2\n",
      "Iteration 0: loss = 3.4528517723083496\n",
      "Iteration 100: loss = 3.4528138637542725\n",
      "Iteration 200: loss = 3.4527764320373535\n",
      "Iteration 300: loss = 3.4527387619018555\n",
      "Optimizing weights and thresholds, round 3\n",
      "Iteration 0: loss = 3.452738046646118\n",
      "Iteration 100: loss = 3.3611505031585693\n",
      "Iteration 200: loss = 3.277255058288574\n",
      "Iteration 300: loss = 3.200808525085449\n",
      "Optimizing item vectors, round 3\n",
      "Iteration 0: loss = 3.200080633163452\n",
      "Iteration 100: loss = 3.2000691890716553\n",
      "Iteration 200: loss = 3.2000577449798584\n",
      "Iteration 300: loss = 3.2000463008880615\n",
      "Optimizing weights and thresholds, round 4\n",
      "Iteration 0: loss = 3.2000460624694824\n",
      "Iteration 100: loss = 3.1474850177764893\n",
      "Iteration 200: loss = 3.0987954139709473\n",
      "Iteration 300: loss = 3.053809881210327\n",
      "Optimizing item vectors, round 4\n",
      "Iteration 0: loss = 3.053377866744995\n",
      "Iteration 100: loss = 3.053373336791992\n",
      "Iteration 200: loss = 3.0533690452575684\n",
      "Iteration 300: loss = 3.0533640384674072\n",
      "Optimizing weights and thresholds, round 5\n",
      "Iteration 0: loss = 3.0533640384674072\n",
      "Iteration 100: loss = 3.0199506282806396\n",
      "Iteration 200: loss = 2.988689422607422\n",
      "Iteration 300: loss = 2.959477663040161\n",
      "Optimizing item vectors, round 5\n",
      "Iteration 0: loss = 2.959195375442505\n",
      "Iteration 100: loss = 2.959193229675293\n",
      "Iteration 200: loss = 2.959191083908081\n",
      "Iteration 300: loss = 2.959188938140869\n",
      "Optimizing weights and thresholds, round 6\n",
      "Iteration 0: loss = 2.959188938140869\n",
      "Iteration 100: loss = 2.9363512992858887\n",
      "Iteration 200: loss = 2.914799213409424\n",
      "Iteration 300: loss = 2.8944711685180664\n",
      "Optimizing item vectors, round 6\n",
      "Iteration 0: loss = 2.8942737579345703\n",
      "Iteration 100: loss = 2.894272804260254\n",
      "Iteration 200: loss = 2.8942716121673584\n",
      "Iteration 300: loss = 2.894270181655884\n",
      "Optimizing weights and thresholds, round 7\n",
      "Iteration 0: loss = 2.894270181655884\n",
      "Iteration 100: loss = 2.8777832984924316\n",
      "Iteration 200: loss = 2.862109899520874\n",
      "Iteration 300: loss = 2.847212553024292\n",
      "Optimizing item vectors, round 7\n",
      "Iteration 0: loss = 2.847067356109619\n",
      "Iteration 100: loss = 2.847066640853882\n",
      "Iteration 200: loss = 2.8470659255981445\n",
      "Iteration 300: loss = 2.8470652103424072\n",
      "Optimizing weights and thresholds, round 8\n",
      "Iteration 0: loss = 2.8470652103424072\n",
      "Iteration 100: loss = 2.8346433639526367\n",
      "Iteration 200: loss = 2.822761058807373\n",
      "Iteration 300: loss = 2.811394691467285\n",
      "Optimizing item vectors, round 8\n",
      "Iteration 0: loss = 2.811283588409424\n",
      "Iteration 100: loss = 2.8112831115722656\n",
      "Iteration 200: loss = 2.8112826347351074\n",
      "Iteration 300: loss = 2.811282157897949\n",
      "Optimizing weights and thresholds, round 9\n",
      "Iteration 0: loss = 2.811282157897949\n",
      "Iteration 100: loss = 2.8015973567962646\n",
      "Iteration 200: loss = 2.7922847270965576\n",
      "Iteration 300: loss = 2.7833285331726074\n",
      "Optimizing item vectors, round 9\n",
      "Iteration 0: loss = 2.7832412719726562\n",
      "Iteration 100: loss = 2.783240556716919\n",
      "Iteration 200: loss = 2.783240556716919\n",
      "Iteration 300: loss = 2.78324031829834\n",
      "<class 'preprocess.DropColumns'>\n",
      "<class 'preprocess.OneHotEncoder'>\n",
      "<class 'preprocess.StandardScaler'>\n",
      "<class 'preprocess.TargetEncoder'>\n",
      "<class 'preprocess.DropColumns'>\n",
      "<class 'preprocess.MinMaxScaler'>\n",
      "<class 'preprocess.SelectOutputColumns'>\n",
      "<class 'preprocess.MeanImputer'>\n",
      "<class 'preprocess.MedianImputer'>\n",
      "<class 'preprocess.OneHotEncoder'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit</th>\n",
       "      <th>price</th>\n",
       "      <th>usually_wear</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>bust_size</th>\n",
       "      <th>cup_size</th>\n",
       "      <th>size_bias</th>\n",
       "      <th>item_weight</th>\n",
       "      <th>...</th>\n",
       "      <th>item_name_4147</th>\n",
       "      <th>item_name_4148</th>\n",
       "      <th>item_name_4149</th>\n",
       "      <th>item_name_4150</th>\n",
       "      <th>item_name_4151</th>\n",
       "      <th>item_name_4152</th>\n",
       "      <th>item_name_4153</th>\n",
       "      <th>item_name_4154</th>\n",
       "      <th>item_name_4155</th>\n",
       "      <th>item_name_4156</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.106092</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.258427</td>\n",
       "      <td>7.979926e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.119150e-01</td>\n",
       "      <td>-8.849729e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.237090</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.293292</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.348315</td>\n",
       "      <td>5.349337e-15</td>\n",
       "      <td>-0.850021</td>\n",
       "      <td>-1.190431e+00</td>\n",
       "      <td>1.443648e+00</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.204525</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.132444</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.573034</td>\n",
       "      <td>5.349337e-15</td>\n",
       "      <td>0.384106</td>\n",
       "      <td>9.666011e-01</td>\n",
       "      <td>1.443648e+00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.604990</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.368583</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>0.393258</td>\n",
       "      <td>7.979926e-01</td>\n",
       "      <td>0.384106</td>\n",
       "      <td>-1.119150e-01</td>\n",
       "      <td>-3.028176e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081798</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.149555</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>0.314607</td>\n",
       "      <td>-1.581297e-01</td>\n",
       "      <td>0.858771</td>\n",
       "      <td>-1.119150e-01</td>\n",
       "      <td>3.190114e+00</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.985914</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87403</th>\n",
       "      <td>1</td>\n",
       "      <td>0.140999</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.361303</td>\n",
       "      <td>5.349337e-15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.831659e-15</td>\n",
       "      <td>2.585289e-16</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.326856</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87404</th>\n",
       "      <td>0</td>\n",
       "      <td>0.032854</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>0.404494</td>\n",
       "      <td>5.349337e-15</td>\n",
       "      <td>0.384106</td>\n",
       "      <td>-1.119150e-01</td>\n",
       "      <td>2.793376e-01</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.055584</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87405</th>\n",
       "      <td>2</td>\n",
       "      <td>0.071869</td>\n",
       "      <td>0.186667</td>\n",
       "      <td>0.483146</td>\n",
       "      <td>1.276054e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.666011e-01</td>\n",
       "      <td>-3.028176e-01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.155005</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87406</th>\n",
       "      <td>0</td>\n",
       "      <td>0.048597</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.292135</td>\n",
       "      <td>-1.581297e-01</td>\n",
       "      <td>-0.802555</td>\n",
       "      <td>-1.119150e-01</td>\n",
       "      <td>-8.849729e-01</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.146586</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87407</th>\n",
       "      <td>1</td>\n",
       "      <td>0.156400</td>\n",
       "      <td>0.213333</td>\n",
       "      <td>0.573034</td>\n",
       "      <td>-1.592313e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.202149e+00</td>\n",
       "      <td>2.793376e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.936886</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87408 rows × 4204 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fit     price  usually_wear       age        height    weight  \\\n",
       "0        1  0.106092      0.080000  0.258427  7.979926e-01  0.000000   \n",
       "1        2  0.293292      0.026667  0.348315  5.349337e-15 -0.850021   \n",
       "2        1  0.132444      0.160000  0.573034  5.349337e-15  0.384106   \n",
       "3        1  0.368583      0.106667  0.393258  7.979926e-01  0.384106   \n",
       "4        2  0.149555      0.106667  0.314607 -1.581297e-01  0.858771   \n",
       "...    ...       ...           ...       ...           ...       ...   \n",
       "87403    1  0.140999      0.080000  0.361303  5.349337e-15  0.000000   \n",
       "87404    0  0.032854      0.106667  0.404494  5.349337e-15  0.384106   \n",
       "87405    2  0.071869      0.186667  0.483146  1.276054e+00  0.000000   \n",
       "87406    0  0.048597      0.026667  0.292135 -1.581297e-01 -0.802555   \n",
       "87407    1  0.156400      0.213333  0.573034 -1.592313e+00  0.000000   \n",
       "\n",
       "          bust_size      cup_size  size_bias  item_weight  ...  \\\n",
       "0     -1.119150e-01 -8.849729e-01        0.0    -0.237090  ...   \n",
       "1     -1.190431e+00  1.443648e+00       -2.0    -1.204525  ...   \n",
       "2      9.666011e-01  1.443648e+00        2.0     0.604990  ...   \n",
       "3     -1.119150e-01 -3.028176e-01        0.0     0.081798  ...   \n",
       "4     -1.119150e-01  3.190114e+00       -1.5     0.985914  ...   \n",
       "...             ...           ...        ...          ...  ...   \n",
       "87403 -3.831659e-15  2.585289e-16        0.5     0.326856  ...   \n",
       "87404 -1.119150e-01  2.793376e-01       -1.0    -1.055584  ...   \n",
       "87405  9.666011e-01 -3.028176e-01        0.5     2.155005  ...   \n",
       "87406 -1.119150e-01 -8.849729e-01       -1.0    -1.146586  ...   \n",
       "87407  4.202149e+00  2.793376e-01        0.0     1.936886  ...   \n",
       "\n",
       "       item_name_4147  item_name_4148  item_name_4149  item_name_4150  \\\n",
       "0                   0               0               0               0   \n",
       "1                   0               0               0               0   \n",
       "2                   0               0               0               0   \n",
       "3                   0               0               0               0   \n",
       "4                   0               0               0               0   \n",
       "...               ...             ...             ...             ...   \n",
       "87403               0               0               0               0   \n",
       "87404               0               0               0               0   \n",
       "87405               0               0               0               0   \n",
       "87406               0               0               0               0   \n",
       "87407               0               0               0               0   \n",
       "\n",
       "       item_name_4151  item_name_4152  item_name_4153  item_name_4154  \\\n",
       "0                   0               0               0               0   \n",
       "1                   0               0               0               0   \n",
       "2                   0               0               0               0   \n",
       "3                   0               0               0               0   \n",
       "4                   0               0               0               0   \n",
       "...               ...             ...             ...             ...   \n",
       "87403               0               0               0               0   \n",
       "87404               0               0               0               0   \n",
       "87405               0               0               0               0   \n",
       "87406               0               0               0               0   \n",
       "87407               0               0               0               0   \n",
       "\n",
       "       item_name_4155  item_name_4156  \n",
       "0                   0               0  \n",
       "1                   0               0  \n",
       "2                   0               0  \n",
       "3                   0               0  \n",
       "4                   0               0  \n",
       "...               ...             ...  \n",
       "87403               0               0  \n",
       "87404               0               0  \n",
       "87405               0               0  \n",
       "87406               0               0  \n",
       "87407               0               0  \n",
       "\n",
       "[87408 rows x 4204 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep.pipeline = [\n",
    "    ##\n",
    "    DropColumns(cols=['user_name', 'review', 'review_summary', 'rating']),\n",
    "    HandleSizeMapping(),  # handle size mapping\n",
    "    OrdinalEncoder(cols=['fit', 'item_name', 'cup_size']),  # (necessary)\n",
    "    MeanImputer(\n",
    "        cols=['weight', 'height', 'bust_size', 'cup_size']),  # (necessary)\n",
    "    ComputeItemVectors(),  # compute item vectors\n",
    "    ##\n",
    "    DropColumns(cols=['size_scheme', 'size']),\n",
    "    OneHotEncoder(cols=['size_suffix', 'rented_for', 'body_type']),\n",
    "    StandardScaler(cols=[\n",
    "        'weight', 'height', 'bust_size', 'cup_size', 'item_weight',\n",
    "        'item_height', 'item_bust_size', 'item_cup_size'\n",
    "    ]),\n",
    "    TargetEncoder(cols=['brand', 'category', 'size_main'],\n",
    "                  target_cols=['weight', 'height', 'bust_size', 'cup_size'],\n",
    "                  name='target_encoder'),\n",
    "    DropColumns(cols=['brand', 'category', 'size_main']),\n",
    "    MinMaxScaler(cols=['age', 'price', 'usually_wear']),\n",
    "    SelectOutputColumns(\n",
    "        target='target_encoder'\n",
    "    ),  # append the output of 'target_encoder' to the input of the next transformer\n",
    "    MeanImputer(cols=['age', 'weight', 'height', 'bust_size', 'cup_size']),\n",
    "    MedianImputer(cols=['price', 'usually_wear']),\n",
    "    OneHotEncoder(cols=['item_name']),\n",
    "    AugmentData\n",
    "]\n",
    "\n",
    "train_df_prep = train_df.copy()\n",
    "test_df_prep = test_df.copy()\n",
    "\n",
    "train_df_prep = prep.fit_transform(train_df_prep)\n",
    "# test_df_prep = prep.transform(test_df_prep)\n",
    "\n",
    "# train_df_prep = prep.compute_item_vectors(train_df_prep, is_train=True)\n",
    "# test_df_prep = prep.compute_item_vectors(test_df_prep)\n",
    "\n",
    "# describe_data(train_df_prep)['nan_count'].sum()\n",
    "# describe_data(train_df_prep)\n",
    "train_df_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtype</th>\n",
       "      <th>valid_count</th>\n",
       "      <th>nan_count</th>\n",
       "      <th>unique_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit</th>\n",
       "      <td>int8</td>\n",
       "      <td>87408</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>float64</td>\n",
       "      <td>87408</td>\n",
       "      <td>0</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usually_wear</th>\n",
       "      <td>float64</td>\n",
       "      <td>87408</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>float64</td>\n",
       "      <td>87408</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>height</th>\n",
       "      <td>float64</td>\n",
       "      <td>87408</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_name_4152</th>\n",
       "      <td>uint8</td>\n",
       "      <td>87408</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_name_4153</th>\n",
       "      <td>uint8</td>\n",
       "      <td>87408</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_name_4154</th>\n",
       "      <td>uint8</td>\n",
       "      <td>87408</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_name_4155</th>\n",
       "      <td>uint8</td>\n",
       "      <td>87408</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_name_4156</th>\n",
       "      <td>uint8</td>\n",
       "      <td>87408</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4204 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  dtype  valid_count  nan_count  unique_count\n",
       "fit                int8        87408          0             3\n",
       "price           float64        87408          0           471\n",
       "usually_wear    float64        87408          0            50\n",
       "age             float64        87408          0            79\n",
       "height          float64        87408          0            25\n",
       "...                 ...          ...        ...           ...\n",
       "item_name_4152    uint8        87408          0             2\n",
       "item_name_4153    uint8        87408          0             2\n",
       "item_name_4154    uint8        87408          0             2\n",
       "item_name_4155    uint8        87408          0             2\n",
       "item_name_4156    uint8        87408          0             2\n",
       "\n",
       "[4204 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe_data(train_df_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import data_augmentation\n",
    "\n",
    "train_df_prep_aug = data_augmentation(\n",
    "    train_df_prep, ['cup_size', 'bust_size', 'weight', 'height'],\n",
    "    ratio_small=3.6,\n",
    "    ratio_large=2.7)\n",
    "\n",
    "X_train, y_train = train_df_prep_aug.drop(\n",
    "    columns=['fit']).values, train_df_prep_aug['fit'].values\n",
    "# X_test, y_test = test_df_prep.drop(\n",
    "#     columns=['fit']).values, test_df_prep['fit'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_train.shape, y_train, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39m# import models\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# importlib.reload(models)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m# from models import LogisticClassifier\u001b[39;00m\n\u001b[1;32m      7\u001b[0m clf \u001b[39m=\u001b[39m LogisticRegression(max_iter\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(clf,\n\u001b[1;32m      9\u001b[0m                             X_train,\n\u001b[1;32m     10\u001b[0m                             y_train,\n\u001b[1;32m     11\u001b[0m                             cv\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,\n\u001b[1;32m     12\u001b[0m                             scoring\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mf1_macro\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     13\u001b[0m                             return_train_score\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     14\u001b[0m                             n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     15\u001b[0m cv_results\n\u001b[1;32m     17\u001b[0m \u001b[39m# clf = LogisticClassifier()\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39m# random_split_aggr(clf, X_train, y_train, X_test, y_test)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39m# random_split_aggr(clf, item_name_train, y_train, item_name_test, y_test)\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m    269\u001b[0m         X,\n\u001b[1;32m    270\u001b[0m         y,\n\u001b[1;32m    271\u001b[0m         scorers,\n\u001b[1;32m    272\u001b[0m         train,\n\u001b[1;32m    273\u001b[0m         test,\n\u001b[1;32m    274\u001b[0m         verbose,\n\u001b[1;32m    275\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    276\u001b[0m         fit_params,\n\u001b[1;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[1;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[1;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    281\u001b[0m     )\n\u001b[1;32m    282\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "# import models\n",
    "# importlib.reload(models)\n",
    "# from models import LogisticClassifier\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "cv_results = cross_validate(clf,\n",
    "                            X_train,\n",
    "                            y_train,\n",
    "                            cv=5,\n",
    "                            scoring='f1_macro',\n",
    "                            return_train_score=True,\n",
    "                            n_jobs=-1)\n",
    "cv_results\n",
    "\n",
    "# clf = LogisticClassifier()\n",
    "# random_split_aggr(clf, X_train, y_train, X_test, y_test)\n",
    "# random_split_aggr(clf, item_name_train, y_train, item_name_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas_profiling import ProfileReport\n",
    "\n",
    "# profile = ProfileReport(test_df, minimal=True)\n",
    "# profile.to_notebook_iframe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OrdinalClassifier copied from StackOverflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import clone\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "class OrdinalClassifier():\n",
    "\n",
    "    def __init__(self, clf):\n",
    "        self.clf = clf\n",
    "        self.clfs = {}\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.unique_class = np.sort(np.unique(y))\n",
    "        if self.unique_class.shape[0] > 2:\n",
    "            for i in range(self.unique_class.shape[0] - 1):\n",
    "                # for each k - 1 ordinal value we fit a binary classification problem\n",
    "                binary_y = (y > self.unique_class[i]).astype(np.uint8)\n",
    "                clf = clone(self.clf)\n",
    "                clf.fit(X, binary_y)\n",
    "                self.clfs[i] = clf\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        clfs_predict = {k: self.clfs[k].predict_proba(X) for k in self.clfs}\n",
    "        predicted = []\n",
    "        for i, y in enumerate(self.unique_class):\n",
    "            if i == 0:\n",
    "                # V1 = 1 - Pr(y > V1)\n",
    "                predicted.append(1 - clfs_predict[i][:, 1])\n",
    "            elif i in clfs_predict:\n",
    "                # Vi = Pr(y > Vi-1) - Pr(y > Vi)\n",
    "                predicted.append(clfs_predict[i - 1][:, 1] -\n",
    "                                 clfs_predict[i][:, 1])\n",
    "            else:\n",
    "                # Vk = Pr(y > Vk-1)\n",
    "                predicted.append(clfs_predict[i - 1][:, 1])\n",
    "        return np.vstack(predicted).T\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.predict_proba(X), axis=1)\n",
    "\n",
    "\n",
    "model = OrdinalClassifier(LogisticRegression(max_iter=2000))\n",
    "model.fit(train_df_prep.drop('fit', axis=1), train_df_prep['fit'])\n",
    "y_pred = model.predict(test_df_prep.drop('fit', axis=1))\n",
    "\n",
    "evaluate_model(test_df_prep['fit'], y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Logistic Regression with sklearn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto ML with PyCaret (Incorrect Metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *\n",
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    setup(\n",
    "        data=train_df_prep,\n",
    "        test_data=test_df_prep,\n",
    "        target='fit',\n",
    "        preprocess=False,\n",
    "        session_id=0,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model('lr', cross_validation=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "input_dim = train_df_prep.drop('fit', axis=1).shape[1]\n",
    "output_dim = 3\n",
    "inputs = torch.tensor(train_df_prep.drop('fit', axis=1).values,\n",
    "                      dtype=torch.float32)\n",
    "labels = torch.tensor(train_df_prep['fit'].values, dtype=torch.long)\n",
    "\n",
    "\n",
    "# Define the model\n",
    "class LogisticRegression(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "num_epochs = 100\n",
    "learning_rate = 0.01\n",
    "lamda = 1\n",
    "\n",
    "# Define the loss function and the optimizer\n",
    "model = LogisticRegression(input_dim, output_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels) + lamda * torch.norm(model.linear.weight)\n",
    "\n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Test the model\n",
    "with torch.no_grad():\n",
    "    predicted = model(\n",
    "        torch.tensor(test_df_prep.drop('fit', axis=1).values,\n",
    "                     dtype=torch.float32))\n",
    "    _, predicted = torch.max(predicted.data, 1)\n",
    "    y_pred = predicted.numpy()\n",
    "\n",
    "evaluate_model(test_df_prep['fit'], y_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d25da615e19396787fe4ca1ac6e145a6d087d3a93322fbf7b59c4188e44aa5c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
