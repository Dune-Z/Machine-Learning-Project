{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtype</th>\n",
       "      <th>valid_count</th>\n",
       "      <th>nan_count</th>\n",
       "      <th>unique_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit</th>\n",
       "      <td>category</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_name</th>\n",
       "      <td>object</td>\n",
       "      <td>17511</td>\n",
       "      <td>42</td>\n",
       "      <td>3604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand</th>\n",
       "      <td>object</td>\n",
       "      <td>17518</td>\n",
       "      <td>35</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>object</td>\n",
       "      <td>17511</td>\n",
       "      <td>42</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size</th>\n",
       "      <td>object</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size_main</th>\n",
       "      <td>object</td>\n",
       "      <td>16194</td>\n",
       "      <td>1359</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size_suffix</th>\n",
       "      <td>object</td>\n",
       "      <td>2387</td>\n",
       "      <td>15166</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size_scheme</th>\n",
       "      <td>object</td>\n",
       "      <td>17437</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>float64</td>\n",
       "      <td>17511</td>\n",
       "      <td>42</td>\n",
       "      <td>454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rented_for</th>\n",
       "      <td>object</td>\n",
       "      <td>16064</td>\n",
       "      <td>1489</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usually_wear</th>\n",
       "      <td>float64</td>\n",
       "      <td>17389</td>\n",
       "      <td>164</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>float64</td>\n",
       "      <td>17054</td>\n",
       "      <td>499</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>height</th>\n",
       "      <td>float64</td>\n",
       "      <td>11067</td>\n",
       "      <td>6486</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>float64</td>\n",
       "      <td>14069</td>\n",
       "      <td>3484</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body_type</th>\n",
       "      <td>object</td>\n",
       "      <td>12284</td>\n",
       "      <td>5269</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bust_size</th>\n",
       "      <td>float64</td>\n",
       "      <td>14767</td>\n",
       "      <td>2786</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cup_size</th>\n",
       "      <td>category</td>\n",
       "      <td>14767</td>\n",
       "      <td>2786</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dtype  valid_count  nan_count  unique_count\n",
       "fit           category        17553          0             3\n",
       "item_name       object        17511         42          3604\n",
       "brand           object        17518         35           515\n",
       "category        object        17511         42            68\n",
       "size            object        17553          0           137\n",
       "size_main       object        16194       1359            52\n",
       "size_suffix     object         2387      15166             5\n",
       "size_scheme     object        17437        116             4\n",
       "price          float64        17511         42           454\n",
       "rented_for      object        16064       1489             8\n",
       "usually_wear   float64        17389        164            24\n",
       "age            float64        17054        499            62\n",
       "height         float64        11067       6486            21\n",
       "weight         float64        14069       3484           152\n",
       "body_type       object        12284       5269             7\n",
       "bust_size      float64        14767       2786            11\n",
       "cup_size      category        14767       2786            13"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "mpl.rcParams['font.family'] = ['serif']\n",
    "mpl.rcParams['font.serif'] = ['Times New Roman']\n",
    "mpl.rcParams['mathtext.fontset'] = 'cm'\n",
    "\n",
    "import utils\n",
    "import preprocess\n",
    "\n",
    "importlib.reload(utils)\n",
    "importlib.reload(preprocess)\n",
    "\n",
    "from utils import fetch_train_data, describe_data, evaluate_model, train_test_split, random_split_aggr\n",
    "from preprocess import *\n",
    "\n",
    "df = fetch_train_data(path='../data/train_data_all_filled.json')\n",
    "# df = fetch_train_data()\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "\n",
    "prep = Preprocessor()\n",
    "train_df = prep.cleanse(train_df, is_train=True)\n",
    "test_df = prep.cleanse(test_df)\n",
    "\n",
    "train_df.dropna(subset=['fit'], inplace=True)\n",
    "test_df.dropna(subset=['fit'], inplace=True)\n",
    "\n",
    "describe_data(test_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'preprocess.DropColumns'>\n",
      "<class 'preprocess.HandleSizeMapping'>\n",
      "<class 'preprocess.OrdinalEncoder'>\n",
      "<class 'preprocess.MeanImputer'>\n",
      "<class 'preprocess.ComputeItemVectors'>\n",
      "Optimizing weights and thresholds, round 1\n",
      "Iteration 0: loss = 14.699899673461914\n",
      "Iteration 100: loss = 7.130328178405762\n",
      "Iteration 200: loss = 4.596743583679199\n",
      "Iteration 300: loss = 3.9746382236480713\n",
      "Optimizing item vectors, round 1\n",
      "Iteration 0: loss = 3.9704017639160156\n",
      "Iteration 100: loss = 3.9702115058898926\n",
      "Iteration 200: loss = 3.970022439956665\n",
      "Iteration 300: loss = 3.9698333740234375\n",
      "Optimizing weights and thresholds, round 2\n",
      "Iteration 0: loss = 3.9698314666748047\n",
      "Iteration 100: loss = 3.7763748168945312\n",
      "Iteration 200: loss = 3.6078250408172607\n",
      "Iteration 300: loss = 3.4580132961273193\n",
      "Optimizing item vectors, round 2\n",
      "Iteration 0: loss = 3.456603527069092\n",
      "Iteration 100: loss = 3.4565675258636475\n",
      "Iteration 200: loss = 3.4565324783325195\n",
      "Iteration 300: loss = 3.4564969539642334\n",
      "Optimizing weights and thresholds, round 3\n",
      "Iteration 0: loss = 3.4564969539642334\n",
      "Iteration 100: loss = 3.366330623626709\n",
      "Iteration 200: loss = 3.283531904220581\n",
      "Iteration 300: loss = 3.2078728675842285\n",
      "Optimizing item vectors, round 3\n",
      "Iteration 0: loss = 3.2071516513824463\n",
      "Iteration 100: loss = 3.2071406841278076\n",
      "Iteration 200: loss = 3.207129955291748\n",
      "Iteration 300: loss = 3.2071187496185303\n",
      "Optimizing weights and thresholds, round 4\n",
      "Iteration 0: loss = 3.207118511199951\n",
      "Iteration 100: loss = 3.1549572944641113\n",
      "Iteration 200: loss = 3.106519937515259\n",
      "Iteration 300: loss = 3.0616538524627686\n",
      "Optimizing item vectors, round 4\n",
      "Iteration 0: loss = 3.061222553253174\n",
      "Iteration 100: loss = 3.061218023300171\n",
      "Iteration 200: loss = 3.061213731765747\n",
      "Iteration 300: loss = 3.061209201812744\n",
      "Optimizing weights and thresholds, round 5\n",
      "Iteration 0: loss = 3.061209201812744\n",
      "Iteration 100: loss = 3.0278048515319824\n",
      "Iteration 200: loss = 2.996485471725464\n",
      "Iteration 300: loss = 2.967156171798706\n",
      "Optimizing item vectors, round 5\n",
      "Iteration 0: loss = 2.9668729305267334\n",
      "Iteration 100: loss = 2.9668707847595215\n",
      "Iteration 200: loss = 2.9668684005737305\n",
      "Iteration 300: loss = 2.9668664932250977\n",
      "Optimizing weights and thresholds, round 6\n",
      "Iteration 0: loss = 2.9668664932250977\n",
      "Iteration 100: loss = 2.9438910484313965\n",
      "Iteration 200: loss = 2.9221713542938232\n",
      "Iteration 300: loss = 2.90164852142334\n",
      "Optimizing item vectors, round 6\n",
      "Iteration 0: loss = 2.901449203491211\n",
      "Iteration 100: loss = 2.9014480113983154\n",
      "Iteration 200: loss = 2.90144681930542\n",
      "Iteration 300: loss = 2.9014456272125244\n",
      "Optimizing weights and thresholds, round 7\n",
      "Iteration 0: loss = 2.9014456272125244\n",
      "Iteration 100: loss = 2.8847737312316895\n",
      "Iteration 200: loss = 2.8689019680023193\n",
      "Iteration 300: loss = 2.8537938594818115\n",
      "Optimizing item vectors, round 7\n",
      "Iteration 0: loss = 2.853646755218506\n",
      "Iteration 100: loss = 2.8536460399627686\n",
      "Iteration 200: loss = 2.8536453247070312\n",
      "Iteration 300: loss = 2.853644609451294\n",
      "Optimizing weights and thresholds, round 8\n",
      "Iteration 0: loss = 2.853644609451294\n",
      "Iteration 100: loss = 2.8410308361053467\n",
      "Iteration 200: loss = 2.828951120376587\n",
      "Iteration 300: loss = 2.817383289337158\n",
      "Optimizing item vectors, round 8\n",
      "Iteration 0: loss = 2.817270040512085\n",
      "Iteration 100: loss = 2.8172695636749268\n",
      "Iteration 200: loss = 2.8172693252563477\n",
      "Iteration 300: loss = 2.8172688484191895\n",
      "Optimizing weights and thresholds, round 9\n",
      "Iteration 0: loss = 2.8172688484191895\n",
      "Iteration 100: loss = 2.807401418685913\n",
      "Iteration 200: loss = 2.797905445098877\n",
      "Iteration 300: loss = 2.7887649536132812\n",
      "Optimizing item vectors, round 9\n",
      "Iteration 0: loss = 2.788675546646118\n",
      "Iteration 100: loss = 2.78867506980896\n",
      "Iteration 200: loss = 2.788674831390381\n",
      "Iteration 300: loss = 2.7886743545532227\n",
      "<class 'preprocess.DropColumns'>\n",
      "<class 'preprocess.OneHotEncoder'>\n",
      "<class 'preprocess.StandardScaler'>\n",
      "<class 'preprocess.TargetEncoder'>\n",
      "<class 'preprocess.DropColumns'>\n",
      "<class 'preprocess.MinMaxScaler'>\n",
      "<class 'preprocess.SelectOutputColumns'>\n",
      "<class 'preprocess.MeanImputer'>\n",
      "<class 'preprocess.MedianImputer'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit</th>\n",
       "      <th>item_name</th>\n",
       "      <th>price</th>\n",
       "      <th>usually_wear</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>bust_size</th>\n",
       "      <th>cup_size</th>\n",
       "      <th>size_bias</th>\n",
       "      <th>...</th>\n",
       "      <th>brand_bust_size</th>\n",
       "      <th>brand_cup_size</th>\n",
       "      <th>category_weight</th>\n",
       "      <th>category_height</th>\n",
       "      <th>category_bust_size</th>\n",
       "      <th>category_cup_size</th>\n",
       "      <th>size_main_weight</th>\n",
       "      <th>size_main_height</th>\n",
       "      <th>size_main_bust_size</th>\n",
       "      <th>size_main_cup_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>193</td>\n",
       "      <td>0.106092</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.258427</td>\n",
       "      <td>0.799328</td>\n",
       "      <td>1.486153e-15</td>\n",
       "      <td>-0.111270</td>\n",
       "      <td>-0.887221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.217710</td>\n",
       "      <td>-0.078844</td>\n",
       "      <td>-0.001785</td>\n",
       "      <td>-0.019965</td>\n",
       "      <td>0.006224</td>\n",
       "      <td>0.025498</td>\n",
       "      <td>-0.449692</td>\n",
       "      <td>-0.107182</td>\n",
       "      <td>-0.372788</td>\n",
       "      <td>-0.195148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2753</td>\n",
       "      <td>0.293292</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.348315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.497469e-01</td>\n",
       "      <td>-1.187556</td>\n",
       "      <td>1.445851</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029302</td>\n",
       "      <td>0.013082</td>\n",
       "      <td>0.070291</td>\n",
       "      <td>0.061561</td>\n",
       "      <td>0.040798</td>\n",
       "      <td>-0.007994</td>\n",
       "      <td>-0.640293</td>\n",
       "      <td>-0.193754</td>\n",
       "      <td>-0.506089</td>\n",
       "      <td>-0.230679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3756</td>\n",
       "      <td>0.132444</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.573034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.835922e-01</td>\n",
       "      <td>0.965016</td>\n",
       "      <td>1.445851</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109378</td>\n",
       "      <td>-0.131329</td>\n",
       "      <td>-0.021097</td>\n",
       "      <td>-0.012278</td>\n",
       "      <td>-0.010151</td>\n",
       "      <td>-0.012040</td>\n",
       "      <td>1.338481</td>\n",
       "      <td>0.258225</td>\n",
       "      <td>1.106327</td>\n",
       "      <td>0.574419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2374</td>\n",
       "      <td>0.368583</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>0.393258</td>\n",
       "      <td>0.799328</td>\n",
       "      <td>3.835922e-01</td>\n",
       "      <td>-0.111270</td>\n",
       "      <td>-0.303953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001317</td>\n",
       "      <td>0.176474</td>\n",
       "      <td>0.070291</td>\n",
       "      <td>0.061561</td>\n",
       "      <td>0.040798</td>\n",
       "      <td>-0.007994</td>\n",
       "      <td>0.572816</td>\n",
       "      <td>0.229287</td>\n",
       "      <td>0.431045</td>\n",
       "      <td>0.250275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>519</td>\n",
       "      <td>0.149555</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>0.314607</td>\n",
       "      <td>-0.156860</td>\n",
       "      <td>8.579533e-01</td>\n",
       "      <td>-0.111270</td>\n",
       "      <td>3.195655</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107591</td>\n",
       "      <td>0.107073</td>\n",
       "      <td>0.073692</td>\n",
       "      <td>0.064940</td>\n",
       "      <td>0.041734</td>\n",
       "      <td>0.060221</td>\n",
       "      <td>-0.112403</td>\n",
       "      <td>0.099056</td>\n",
       "      <td>-0.093288</td>\n",
       "      <td>-0.051093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69917</th>\n",
       "      <td>1</td>\n",
       "      <td>2607</td>\n",
       "      <td>0.077687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280899</td>\n",
       "      <td>-1.113047</td>\n",
       "      <td>1.486153e-15</td>\n",
       "      <td>-1.187556</td>\n",
       "      <td>-1.470489</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051393</td>\n",
       "      <td>-0.002144</td>\n",
       "      <td>-0.001785</td>\n",
       "      <td>-0.019965</td>\n",
       "      <td>0.006224</td>\n",
       "      <td>0.025498</td>\n",
       "      <td>-0.952809</td>\n",
       "      <td>-0.481843</td>\n",
       "      <td>-0.719651</td>\n",
       "      <td>-0.392399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69918</th>\n",
       "      <td>1</td>\n",
       "      <td>586</td>\n",
       "      <td>0.120465</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>0.382022</td>\n",
       "      <td>1.755516</td>\n",
       "      <td>1.486153e-15</td>\n",
       "      <td>-0.111270</td>\n",
       "      <td>0.279315</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059137</td>\n",
       "      <td>0.041865</td>\n",
       "      <td>0.059882</td>\n",
       "      <td>0.019612</td>\n",
       "      <td>0.038804</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.224981</td>\n",
       "      <td>0.120939</td>\n",
       "      <td>0.156000</td>\n",
       "      <td>0.098727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69919</th>\n",
       "      <td>2</td>\n",
       "      <td>3335</td>\n",
       "      <td>0.278234</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.348315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.276672e+00</td>\n",
       "      <td>-2.263841</td>\n",
       "      <td>0.279315</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050860</td>\n",
       "      <td>-0.031520</td>\n",
       "      <td>0.070291</td>\n",
       "      <td>0.061561</td>\n",
       "      <td>0.040798</td>\n",
       "      <td>-0.007994</td>\n",
       "      <td>0.224981</td>\n",
       "      <td>0.120939</td>\n",
       "      <td>0.156000</td>\n",
       "      <td>0.098727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69920</th>\n",
       "      <td>1</td>\n",
       "      <td>3367</td>\n",
       "      <td>0.122177</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.382022</td>\n",
       "      <td>-0.156860</td>\n",
       "      <td>-8.023108e-01</td>\n",
       "      <td>-0.111270</td>\n",
       "      <td>-0.887221</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254435</td>\n",
       "      <td>0.090483</td>\n",
       "      <td>-0.021097</td>\n",
       "      <td>-0.012278</td>\n",
       "      <td>-0.010151</td>\n",
       "      <td>-0.012040</td>\n",
       "      <td>-0.449692</td>\n",
       "      <td>-0.107182</td>\n",
       "      <td>-0.372788</td>\n",
       "      <td>-0.195148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69921</th>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>0.065708</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>0.361493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.486153e-15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031951</td>\n",
       "      <td>-0.128322</td>\n",
       "      <td>-0.001785</td>\n",
       "      <td>-0.019965</td>\n",
       "      <td>0.006224</td>\n",
       "      <td>0.025498</td>\n",
       "      <td>0.116827</td>\n",
       "      <td>0.135960</td>\n",
       "      <td>0.064341</td>\n",
       "      <td>0.020087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69922 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fit  item_name     price  usually_wear       age    height  \\\n",
       "0        1        193  0.106092      0.080000  0.258427  0.799328   \n",
       "1        2       2753  0.293292      0.026667  0.348315  0.000000   \n",
       "2        1       3756  0.132444      0.160000  0.573034  0.000000   \n",
       "3        1       2374  0.368583      0.106667  0.393258  0.799328   \n",
       "4        2        519  0.149555      0.106667  0.314607 -0.156860   \n",
       "...    ...        ...       ...           ...       ...       ...   \n",
       "69917    1       2607  0.077687      0.000000  0.280899 -1.113047   \n",
       "69918    1        586  0.120465      0.106667  0.382022  1.755516   \n",
       "69919    2       3335  0.278234      0.026667  0.348315  0.000000   \n",
       "69920    1       3367  0.122177      0.080000  0.382022 -0.156860   \n",
       "69921    1        577  0.065708      0.106667  0.361493  0.000000   \n",
       "\n",
       "             weight  bust_size  cup_size  size_bias  ...  brand_bust_size  \\\n",
       "0      1.486153e-15  -0.111270 -0.887221        0.0  ...        -0.217710   \n",
       "1     -8.497469e-01  -1.187556  1.445851       -2.0  ...        -0.029302   \n",
       "2      3.835922e-01   0.965016  1.445851        2.0  ...        -0.109378   \n",
       "3      3.835922e-01  -0.111270 -0.303953        0.0  ...        -0.001317   \n",
       "4      8.579533e-01  -0.111270  3.195655       -1.0  ...         0.107591   \n",
       "...             ...        ...       ...        ...  ...              ...   \n",
       "69917  1.486153e-15  -1.187556 -1.470489       -2.0  ...        -0.051393   \n",
       "69918  1.486153e-15  -0.111270  0.279315        0.5  ...         0.059137   \n",
       "69919 -1.276672e+00  -2.263841  0.279315       -1.5  ...        -0.050860   \n",
       "69920 -8.023108e-01  -0.111270 -0.887221       -1.5  ...         0.254435   \n",
       "69921  1.486153e-15   0.000000  0.000000        0.5  ...        -0.031951   \n",
       "\n",
       "       brand_cup_size  category_weight  category_height  category_bust_size  \\\n",
       "0           -0.078844        -0.001785        -0.019965            0.006224   \n",
       "1            0.013082         0.070291         0.061561            0.040798   \n",
       "2           -0.131329        -0.021097        -0.012278           -0.010151   \n",
       "3            0.176474         0.070291         0.061561            0.040798   \n",
       "4            0.107073         0.073692         0.064940            0.041734   \n",
       "...               ...              ...              ...                 ...   \n",
       "69917       -0.002144        -0.001785        -0.019965            0.006224   \n",
       "69918        0.041865         0.059882         0.019612            0.038804   \n",
       "69919       -0.031520         0.070291         0.061561            0.040798   \n",
       "69920        0.090483        -0.021097        -0.012278           -0.010151   \n",
       "69921       -0.128322        -0.001785        -0.019965            0.006224   \n",
       "\n",
       "       category_cup_size  size_main_weight  size_main_height  \\\n",
       "0               0.025498         -0.449692         -0.107182   \n",
       "1              -0.007994         -0.640293         -0.193754   \n",
       "2              -0.012040          1.338481          0.258225   \n",
       "3              -0.007994          0.572816          0.229287   \n",
       "4               0.060221         -0.112403          0.099056   \n",
       "...                  ...               ...               ...   \n",
       "69917           0.025498         -0.952809         -0.481843   \n",
       "69918           0.001096          0.224981          0.120939   \n",
       "69919          -0.007994          0.224981          0.120939   \n",
       "69920          -0.012040         -0.449692         -0.107182   \n",
       "69921           0.025498          0.116827          0.135960   \n",
       "\n",
       "       size_main_bust_size  size_main_cup_size  \n",
       "0                -0.372788           -0.195148  \n",
       "1                -0.506089           -0.230679  \n",
       "2                 1.106327            0.574419  \n",
       "3                 0.431045            0.250275  \n",
       "4                -0.093288           -0.051093  \n",
       "...                    ...                 ...  \n",
       "69917            -0.719651           -0.392399  \n",
       "69918             0.156000            0.098727  \n",
       "69919             0.156000            0.098727  \n",
       "69920            -0.372788           -0.195148  \n",
       "69921             0.064341            0.020087  \n",
       "\n",
       "[69922 rows x 48 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep.pipeline = [\n",
    "    ##\n",
    "    DropColumns(cols=['user_name', 'review', 'review_summary', 'rating']),\n",
    "    HandleSizeMapping(),  # handle size mapping\n",
    "    OrdinalEncoder(cols=['fit', 'item_name', 'cup_size']),  # (necessary)\n",
    "    MeanImputer(\n",
    "        cols=['weight', 'height', 'bust_size', 'cup_size']),  # (necessary)\n",
    "    ComputeItemVectors(),  # compute item vectors\n",
    "    ##\n",
    "    DropColumns(cols=['size_scheme', 'size']),\n",
    "    OneHotEncoder(cols=['size_suffix', 'rented_for', 'body_type']),\n",
    "    StandardScaler(cols=[\n",
    "        'weight', 'height', 'bust_size', 'cup_size', 'item_weight',\n",
    "        'item_height', 'item_bust_size', 'item_cup_size'\n",
    "    ]),\n",
    "    TargetEncoder(cols=['brand', 'category', 'size_main'],\n",
    "                  target_cols=['weight', 'height', 'bust_size', 'cup_size'],\n",
    "                  name='target_encoder'),\n",
    "    DropColumns(cols=['brand', 'category', 'size_main']),\n",
    "    MinMaxScaler(cols=['age', 'price', 'usually_wear']),\n",
    "    SelectOutputColumns(\n",
    "        target='target_encoder'\n",
    "    ),  # append the output of 'target_encoder' to the input of the next transformer\n",
    "    MeanImputer(cols=['age', 'weight', 'height', 'bust_size', 'cup_size']),\n",
    "    MedianImputer(cols=['price', 'usually_wear']),\n",
    "    # OneHotEncoder(cols=['item_name']),\n",
    "]\n",
    "\n",
    "train_df_prep, test_df_prep = train_df.copy(), test_df.copy()\n",
    "\n",
    "train_df_prep = prep.fit_transform(train_df_prep)\n",
    "test_df_prep = prep.transform(test_df_prep)\n",
    "\n",
    "# train_df_prep = prep.compute_item_vectors(train_df_prep, is_train=True)\n",
    "# test_df_prep = prep.compute_item_vectors(test_df_prep)\n",
    "\n",
    "# describe_data(train_df_prep)['nan_count'].sum()\n",
    "# describe_data(train_df_prep)\n",
    "train_df_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtype</th>\n",
       "      <th>valid_count</th>\n",
       "      <th>nan_count</th>\n",
       "      <th>unique_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit</th>\n",
       "      <td>int8</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_name</th>\n",
       "      <td>float64</td>\n",
       "      <td>17411</td>\n",
       "      <td>142</td>\n",
       "      <td>3511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>float64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usually_wear</th>\n",
       "      <td>float64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>float64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>height</th>\n",
       "      <td>float64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>float64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bust_size</th>\n",
       "      <td>float64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cup_size</th>\n",
       "      <td>float64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size_bias</th>\n",
       "      <td>float64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_weight</th>\n",
       "      <td>float32</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>10100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_height</th>\n",
       "      <td>float32</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>9689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_bust_size</th>\n",
       "      <td>float32</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>9777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_cup_size</th>\n",
       "      <td>float32</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>10232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size_suffix_R</th>\n",
       "      <td>int64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size_suffix_L</th>\n",
       "      <td>int64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size_suffix_P</th>\n",
       "      <td>int64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size_suffix_W</th>\n",
       "      <td>int64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size_suffix_WR</th>\n",
       "      <td>int64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size_suffix_WL</th>\n",
       "      <td>int64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size_suffix_WP</th>\n",
       "      <td>int64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rented_for_Everyday</th>\n",
       "      <td>int64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rented_for_Work</th>\n",
       "      <td>int64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rented_for_Party</th>\n",
       "      <td>int64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rented_for_Other</th>\n",
       "      <td>int64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rented_for_Vacation</th>\n",
       "      <td>int64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rented_for_Date</th>\n",
       "      <td>int64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rented_for_Wedding</th>\n",
       "      <td>int64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rented_for_Formal Affair</th>\n",
       "      <td>int64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body_type_HOURGLASS</th>\n",
       "      <td>int64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body_type_ATHLETIC</th>\n",
       "      <td>int64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body_type_PEAR</th>\n",
       "      <td>int64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body_type_PETITE</th>\n",
       "      <td>int64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body_type_STRAIGHT &amp; NARROW</th>\n",
       "      <td>int64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body_type_FULL BUST</th>\n",
       "      <td>int64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body_type_APPLE</th>\n",
       "      <td>int64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_weight</th>\n",
       "      <td>float64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_height</th>\n",
       "      <td>float64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_bust_size</th>\n",
       "      <td>float64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_cup_size</th>\n",
       "      <td>float64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category_weight</th>\n",
       "      <td>float64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category_height</th>\n",
       "      <td>float64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category_bust_size</th>\n",
       "      <td>float64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category_cup_size</th>\n",
       "      <td>float64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size_main_weight</th>\n",
       "      <td>float64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size_main_height</th>\n",
       "      <td>float64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size_main_bust_size</th>\n",
       "      <td>float64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size_main_cup_size</th>\n",
       "      <td>float64</td>\n",
       "      <td>17553</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               dtype  valid_count  nan_count  unique_count\n",
       "fit                             int8        17553          0             3\n",
       "item_name                    float64        17411        142          3511\n",
       "price                        float64        17553          0           454\n",
       "usually_wear                 float64        17553          0            24\n",
       "age                          float64        17553          0            63\n",
       "height                       float64        17553          0            22\n",
       "weight                       float64        17553          0           153\n",
       "bust_size                    float64        17553          0            12\n",
       "cup_size                     float64        17553          0            14\n",
       "size_bias                    float64        17553          0            39\n",
       "item_weight                  float32        17553          0         10100\n",
       "item_height                  float32        17553          0          9689\n",
       "item_bust_size               float32        17553          0          9777\n",
       "item_cup_size                float32        17553          0         10232\n",
       "size_suffix_R                  int64        17553          0             2\n",
       "size_suffix_L                  int64        17553          0             2\n",
       "size_suffix_P                  int64        17553          0             2\n",
       "size_suffix_W                  int64        17553          0             2\n",
       "size_suffix_WR                 int64        17553          0             2\n",
       "size_suffix_WL                 int64        17553          0             1\n",
       "size_suffix_WP                 int64        17553          0             1\n",
       "rented_for_Everyday            int64        17553          0             2\n",
       "rented_for_Work                int64        17553          0             2\n",
       "rented_for_Party               int64        17553          0             2\n",
       "rented_for_Other               int64        17553          0             2\n",
       "rented_for_Vacation            int64        17553          0             2\n",
       "rented_for_Date                int64        17553          0             2\n",
       "rented_for_Wedding             int64        17553          0             2\n",
       "rented_for_Formal Affair       int64        17553          0             2\n",
       "body_type_HOURGLASS            int64        17553          0             2\n",
       "body_type_ATHLETIC             int64        17553          0             2\n",
       "body_type_PEAR                 int64        17553          0             2\n",
       "body_type_PETITE               int64        17553          0             2\n",
       "body_type_STRAIGHT & NARROW    int64        17553          0             2\n",
       "body_type_FULL BUST            int64        17553          0             2\n",
       "body_type_APPLE                int64        17553          0             2\n",
       "brand_weight                 float64        17553          0           476\n",
       "brand_height                 float64        17553          0           475\n",
       "brand_bust_size              float64        17553          0           471\n",
       "brand_cup_size               float64        17553          0           471\n",
       "category_weight              float64        17553          0            69\n",
       "category_height              float64        17553          0            69\n",
       "category_bust_size           float64        17553          0            68\n",
       "category_cup_size            float64        17553          0            69\n",
       "size_main_weight             float64        17553          0            53\n",
       "size_main_height             float64        17553          0            53\n",
       "size_main_bust_size          float64        17553          0            53\n",
       "size_main_cup_size           float64        17553          0            53"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe_data(test_df_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder as SklearnOneHotEncoder\n",
    "\n",
    "encoder = SklearnOneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "X_train, y_train = train_df_prep.drop(\n",
    "    columns=['fit', 'item_name']).values, train_df_prep['fit'].values\n",
    "X_test, y_test = test_df_prep.drop(\n",
    "    columns=['fit', 'item_name']).values, test_df_prep['fit'].values\n",
    "\n",
    "item_name_train = encoder.fit_transform(train_df_prep[['item_name']].values)\n",
    "item_name_test = encoder.transform(test_df_prep[['item_name']].values)\n",
    "\n",
    "X_train = np.concatenate([X_train, item_name_train], axis=1)\n",
    "X_test = np.concatenate([X_test, item_name_test], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.10609172, 0.08      , 0.25842697, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.29329227, 0.02666667, 0.34831461, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.13244353, 0.16      , 0.57303371, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [0.27823409, 0.02666667, 0.34831461, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.12217659, 0.08      , 0.38202247, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.06570842, 0.10666667, 0.36149299, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " (69922, 4135),\n",
       " array([1, 2, 1, ..., 2, 1, 1], dtype=int8),\n",
       " (69922,))"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_train.shape, y_train, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2], dtype=int8), array([ 9485, 16311, 11505]))\n",
      "(array([0, 1, 2], dtype=int8), array([ 9485, 16311, 11505]))\n",
      "(array([0, 1, 2], dtype=int8), array([ 9485, 16310, 11505]))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>#small</th>\n",
       "      <th>#true2size</th>\n",
       "      <th>#large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>result</th>\n",
       "      <td>0.621603</td>\n",
       "      <td>0.519448</td>\n",
       "      <td>0.573485</td>\n",
       "      <td>0.536164</td>\n",
       "      <td>0.63769</td>\n",
       "      <td>3065</td>\n",
       "      <td>10211</td>\n",
       "      <td>4277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy  precision    recall        f1  f1_weighted  #small  \\\n",
       "result  0.621603   0.519448  0.573485  0.536164      0.63769    3065   \n",
       "\n",
       "        #true2size  #large  \n",
       "result       10211    4277  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(max_iter=5000)\n",
    "random_split_aggr(clf, X_train, y_train, X_test, y_test)\n",
    "# random_split_aggr(clf, item_name_train, y_train, item_name_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas_profiling import ProfileReport\n",
    "\n",
    "# profile = ProfileReport(test_df, minimal=True)\n",
    "# profile.to_notebook_iframe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OrdinalClassifier copied from StackOverflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>#small</th>\n",
       "      <th>#true2size</th>\n",
       "      <th>#large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>result</th>\n",
       "      <td>0.685595</td>\n",
       "      <td>0.404086</td>\n",
       "      <td>0.334269</td>\n",
       "      <td>0.275133</td>\n",
       "      <td>0.560648</td>\n",
       "      <td>9</td>\n",
       "      <td>11898</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy  precision    recall        f1  f1_weighted  #small  \\\n",
       "result  0.685595   0.404086  0.334269  0.275133     0.560648       9   \n",
       "\n",
       "        #true2size  #large  \n",
       "result       11898      33  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import clone\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "class OrdinalClassifier():\n",
    "\n",
    "    def __init__(self, clf):\n",
    "        self.clf = clf\n",
    "        self.clfs = {}\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.unique_class = np.sort(np.unique(y))\n",
    "        if self.unique_class.shape[0] > 2:\n",
    "            for i in range(self.unique_class.shape[0] - 1):\n",
    "                # for each k - 1 ordinal value we fit a binary classification problem\n",
    "                binary_y = (y > self.unique_class[i]).astype(np.uint8)\n",
    "                clf = clone(self.clf)\n",
    "                clf.fit(X, binary_y)\n",
    "                self.clfs[i] = clf\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        clfs_predict = {k: self.clfs[k].predict_proba(X) for k in self.clfs}\n",
    "        predicted = []\n",
    "        for i, y in enumerate(self.unique_class):\n",
    "            if i == 0:\n",
    "                # V1 = 1 - Pr(y > V1)\n",
    "                predicted.append(1 - clfs_predict[i][:, 1])\n",
    "            elif i in clfs_predict:\n",
    "                # Vi = Pr(y > Vi-1) - Pr(y > Vi)\n",
    "                predicted.append(clfs_predict[i - 1][:, 1] -\n",
    "                                 clfs_predict[i][:, 1])\n",
    "            else:\n",
    "                # Vk = Pr(y > Vk-1)\n",
    "                predicted.append(clfs_predict[i - 1][:, 1])\n",
    "        return np.vstack(predicted).T\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.predict_proba(X), axis=1)\n",
    "\n",
    "\n",
    "model = OrdinalClassifier(LogisticRegression(max_iter=2000))\n",
    "model.fit(train_df_prep.drop('fit', axis=1), train_df_prep['fit'])\n",
    "y_pred = model.predict(test_df_prep.drop('fit', axis=1))\n",
    "\n",
    "evaluate_model(test_df_prep['fit'], y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Logistic Regression with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[124], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m model \u001b[39m=\u001b[39m LogisticRegression(max_iter\u001b[39m=\u001b[39m\u001b[39m2000\u001b[39m)\n\u001b[1;32m      4\u001b[0m model\u001b[39m.\u001b[39mfit(train_df_prep\u001b[39m.\u001b[39mdrop(\u001b[39m'\u001b[39m\u001b[39mfit\u001b[39m\u001b[39m'\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), train_df_prep[\u001b[39m'\u001b[39m\u001b[39mfit\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m----> 5\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(test_df_prep\u001b[39m.\u001b[39;49mdrop(\u001b[39m'\u001b[39;49m\u001b[39mfit\u001b[39;49m\u001b[39m'\u001b[39;49m, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m))\n\u001b[1;32m      7\u001b[0m random_split_aggr(test_df_prep[\u001b[39m'\u001b[39m\u001b[39mfit\u001b[39m\u001b[39m'\u001b[39m], y_pred)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/site-packages/sklearn/linear_model/_base.py:447\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    434\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[39m    Predict class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[39m        Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 447\u001b[0m     scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecision_function(X)\n\u001b[1;32m    448\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(scores\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    449\u001b[0m         indices \u001b[39m=\u001b[39m (scores \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/site-packages/sklearn/linear_model/_base.py:429\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[39mPredict confidence scores for samples.\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[39m    this class would be predicted.\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    427\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 429\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    430\u001b[0m scores \u001b[39m=\u001b[39m safe_sparse_dot(X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_\u001b[39m.\u001b[39mT, dense_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_\n\u001b[1;32m    431\u001b[0m \u001b[39mreturn\u001b[39;00m scores\u001b[39m.\u001b[39mravel() \u001b[39mif\u001b[39;00m scores\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m scores\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/site-packages/sklearn/base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    576\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 577\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    578\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    579\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/site-packages/sklearn/utils/validation.py:899\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    894\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    895\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    896\u001b[0m         )\n\u001b[1;32m    898\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 899\u001b[0m         _assert_all_finite(\n\u001b[1;32m    900\u001b[0m             array,\n\u001b[1;32m    901\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    902\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    903\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    904\u001b[0m         )\n\u001b[1;32m    906\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    907\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/site-packages/sklearn/utils/validation.py:146\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    125\u001b[0m             \u001b[39mnot\u001b[39;00m allow_nan\n\u001b[1;32m    126\u001b[0m             \u001b[39mand\u001b[39;00m estimator_name\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    131\u001b[0m             \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m             msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    133\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m             )\n\u001b[0;32m--> 146\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n\u001b[1;32m    148\u001b[0m \u001b[39m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39melif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nan:\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto ML with PyCaret (Incorrect Metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_523c7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_523c7_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_523c7_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_523c7_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_523c7_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_523c7_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_523c7_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_523c7_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_523c7_row1_col1\" class=\"data row1 col1\" >fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_523c7_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_523c7_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_523c7_row2_col1\" class=\"data row2 col1\" >Multiclass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_523c7_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_523c7_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_523c7_row3_col1\" class=\"data row3 col1\" >(59827, 649)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_523c7_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_523c7_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_523c7_row4_col1\" class=\"data row4 col1\" >(59827, 649)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_523c7_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_523c7_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_523c7_row5_col1\" class=\"data row5 col1\" >(47929, 649)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_523c7_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_523c7_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_523c7_row6_col1\" class=\"data row6 col1\" >(11898, 649)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_523c7_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_523c7_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_523c7_row7_col1\" class=\"data row7 col1\" >648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x28784dc00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pycaret.classification import *\n",
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    setup(\n",
    "        data=train_df_prep,\n",
    "        test_data=test_df_prep,\n",
    "        target='fit',\n",
    "        preprocess=False,\n",
    "        session_id=0,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3513d th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_3513d_row0_col0, #T_3513d_row0_col2, #T_3513d_row0_col4, #T_3513d_row0_col5, #T_3513d_row0_col6, #T_3513d_row0_col7, #T_3513d_row1_col0, #T_3513d_row1_col1, #T_3513d_row1_col2, #T_3513d_row1_col3, #T_3513d_row1_col4, #T_3513d_row1_col5, #T_3513d_row1_col6, #T_3513d_row1_col7, #T_3513d_row2_col0, #T_3513d_row2_col1, #T_3513d_row2_col3, #T_3513d_row2_col4, #T_3513d_row2_col5, #T_3513d_row2_col6, #T_3513d_row2_col7, #T_3513d_row3_col0, #T_3513d_row3_col1, #T_3513d_row3_col2, #T_3513d_row3_col3, #T_3513d_row3_col4, #T_3513d_row4_col0, #T_3513d_row4_col1, #T_3513d_row4_col2, #T_3513d_row4_col3, #T_3513d_row4_col4, #T_3513d_row4_col5, #T_3513d_row4_col6, #T_3513d_row4_col7, #T_3513d_row5_col0, #T_3513d_row5_col1, #T_3513d_row5_col2, #T_3513d_row5_col3, #T_3513d_row5_col5, #T_3513d_row5_col6, #T_3513d_row5_col7, #T_3513d_row6_col0, #T_3513d_row6_col1, #T_3513d_row6_col2, #T_3513d_row6_col3, #T_3513d_row6_col4, #T_3513d_row6_col5, #T_3513d_row6_col6, #T_3513d_row6_col7, #T_3513d_row7_col0, #T_3513d_row7_col1, #T_3513d_row7_col2, #T_3513d_row7_col3, #T_3513d_row7_col4, #T_3513d_row7_col5, #T_3513d_row7_col6, #T_3513d_row7_col7, #T_3513d_row8_col0, #T_3513d_row8_col1, #T_3513d_row8_col2, #T_3513d_row8_col3, #T_3513d_row8_col4, #T_3513d_row8_col5, #T_3513d_row8_col6, #T_3513d_row8_col7, #T_3513d_row9_col0, #T_3513d_row9_col1, #T_3513d_row9_col2, #T_3513d_row9_col3, #T_3513d_row9_col4, #T_3513d_row9_col5, #T_3513d_row9_col6, #T_3513d_row9_col7, #T_3513d_row10_col0, #T_3513d_row10_col1, #T_3513d_row10_col2, #T_3513d_row10_col3, #T_3513d_row10_col4, #T_3513d_row10_col5, #T_3513d_row10_col6, #T_3513d_row10_col7, #T_3513d_row11_col0, #T_3513d_row11_col1, #T_3513d_row11_col2, #T_3513d_row11_col3, #T_3513d_row11_col4, #T_3513d_row11_col5, #T_3513d_row11_col6, #T_3513d_row11_col7, #T_3513d_row12_col0, #T_3513d_row12_col1, #T_3513d_row12_col2, #T_3513d_row12_col3, #T_3513d_row12_col4, #T_3513d_row12_col5, #T_3513d_row12_col6, #T_3513d_row12_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_3513d_row0_col1, #T_3513d_row0_col3, #T_3513d_row2_col2, #T_3513d_row3_col5, #T_3513d_row3_col6, #T_3513d_row3_col7, #T_3513d_row5_col4 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_3513d_row0_col8, #T_3513d_row1_col8, #T_3513d_row2_col8, #T_3513d_row3_col8, #T_3513d_row4_col8, #T_3513d_row5_col8, #T_3513d_row6_col8, #T_3513d_row7_col8, #T_3513d_row9_col8, #T_3513d_row10_col8, #T_3513d_row11_col8, #T_3513d_row12_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_3513d_row8_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3513d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3513d_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_3513d_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_3513d_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_3513d_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_3513d_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_3513d_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_3513d_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_3513d_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_3513d_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3513d_level0_row0\" class=\"row_heading level0 row0\" >lr</th>\n",
       "      <td id=\"T_3513d_row0_col0\" class=\"data row0 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_3513d_row0_col1\" class=\"data row0 col1\" >0.6981</td>\n",
       "      <td id=\"T_3513d_row0_col2\" class=\"data row0 col2\" >0.6676</td>\n",
       "      <td id=\"T_3513d_row0_col3\" class=\"data row0 col3\" >0.6981</td>\n",
       "      <td id=\"T_3513d_row0_col4\" class=\"data row0 col4\" >0.6577</td>\n",
       "      <td id=\"T_3513d_row0_col5\" class=\"data row0 col5\" >0.6252</td>\n",
       "      <td id=\"T_3513d_row0_col6\" class=\"data row0 col6\" >0.1582</td>\n",
       "      <td id=\"T_3513d_row0_col7\" class=\"data row0 col7\" >0.2125</td>\n",
       "      <td id=\"T_3513d_row0_col8\" class=\"data row0 col8\" >13.6830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3513d_level0_row1\" class=\"row_heading level0 row1\" >ridge</th>\n",
       "      <td id=\"T_3513d_row1_col0\" class=\"data row1 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_3513d_row1_col1\" class=\"data row1 col1\" >0.6965</td>\n",
       "      <td id=\"T_3513d_row1_col2\" class=\"data row1 col2\" >0.0000</td>\n",
       "      <td id=\"T_3513d_row1_col3\" class=\"data row1 col3\" >0.6965</td>\n",
       "      <td id=\"T_3513d_row1_col4\" class=\"data row1 col4\" >0.6552</td>\n",
       "      <td id=\"T_3513d_row1_col5\" class=\"data row1 col5\" >0.6188</td>\n",
       "      <td id=\"T_3513d_row1_col6\" class=\"data row1 col6\" >0.1442</td>\n",
       "      <td id=\"T_3513d_row1_col7\" class=\"data row1 col7\" >0.2011</td>\n",
       "      <td id=\"T_3513d_row1_col8\" class=\"data row1 col8\" >0.2600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3513d_level0_row2\" class=\"row_heading level0 row2\" >rf</th>\n",
       "      <td id=\"T_3513d_row2_col0\" class=\"data row2 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_3513d_row2_col1\" class=\"data row2 col1\" >0.6930</td>\n",
       "      <td id=\"T_3513d_row2_col2\" class=\"data row2 col2\" >0.6697</td>\n",
       "      <td id=\"T_3513d_row2_col3\" class=\"data row2 col3\" >0.6930</td>\n",
       "      <td id=\"T_3513d_row2_col4\" class=\"data row2 col4\" >0.6711</td>\n",
       "      <td id=\"T_3513d_row2_col5\" class=\"data row2 col5\" >0.5976</td>\n",
       "      <td id=\"T_3513d_row2_col6\" class=\"data row2 col6\" >0.0894</td>\n",
       "      <td id=\"T_3513d_row2_col7\" class=\"data row2 col7\" >0.1595</td>\n",
       "      <td id=\"T_3513d_row2_col8\" class=\"data row2 col8\" >7.1890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3513d_level0_row3\" class=\"row_heading level0 row3\" >lda</th>\n",
       "      <td id=\"T_3513d_row3_col0\" class=\"data row3 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_3513d_row3_col1\" class=\"data row3 col1\" >0.6921</td>\n",
       "      <td id=\"T_3513d_row3_col2\" class=\"data row3 col2\" >0.6654</td>\n",
       "      <td id=\"T_3513d_row3_col3\" class=\"data row3 col3\" >0.6921</td>\n",
       "      <td id=\"T_3513d_row3_col4\" class=\"data row3 col4\" >0.6463</td>\n",
       "      <td id=\"T_3513d_row3_col5\" class=\"data row3 col5\" >0.6377</td>\n",
       "      <td id=\"T_3513d_row3_col6\" class=\"data row3 col6\" >0.1922</td>\n",
       "      <td id=\"T_3513d_row3_col7\" class=\"data row3 col7\" >0.2245</td>\n",
       "      <td id=\"T_3513d_row3_col8\" class=\"data row3 col8\" >3.9180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3513d_level0_row4\" class=\"row_heading level0 row4\" >svm</th>\n",
       "      <td id=\"T_3513d_row4_col0\" class=\"data row4 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_3513d_row4_col1\" class=\"data row4 col1\" >0.6920</td>\n",
       "      <td id=\"T_3513d_row4_col2\" class=\"data row4 col2\" >0.0000</td>\n",
       "      <td id=\"T_3513d_row4_col3\" class=\"data row4 col3\" >0.6920</td>\n",
       "      <td id=\"T_3513d_row4_col4\" class=\"data row4 col4\" >0.6429</td>\n",
       "      <td id=\"T_3513d_row4_col5\" class=\"data row4 col5\" >0.6032</td>\n",
       "      <td id=\"T_3513d_row4_col6\" class=\"data row4 col6\" >0.1111</td>\n",
       "      <td id=\"T_3513d_row4_col7\" class=\"data row4 col7\" >0.1712</td>\n",
       "      <td id=\"T_3513d_row4_col8\" class=\"data row4 col8\" >1.7510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3513d_level0_row5\" class=\"row_heading level0 row5\" >gbc</th>\n",
       "      <td id=\"T_3513d_row5_col0\" class=\"data row5 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_3513d_row5_col1\" class=\"data row5 col1\" >0.6886</td>\n",
       "      <td id=\"T_3513d_row5_col2\" class=\"data row5 col2\" >0.6495</td>\n",
       "      <td id=\"T_3513d_row5_col3\" class=\"data row5 col3\" >0.6886</td>\n",
       "      <td id=\"T_3513d_row5_col4\" class=\"data row5 col4\" >0.7034</td>\n",
       "      <td id=\"T_3513d_row5_col5\" class=\"data row5 col5\" >0.5724</td>\n",
       "      <td id=\"T_3513d_row5_col6\" class=\"data row5 col6\" >0.0373</td>\n",
       "      <td id=\"T_3513d_row5_col7\" class=\"data row5 col7\" >0.1124</td>\n",
       "      <td id=\"T_3513d_row5_col8\" class=\"data row5 col8\" >27.3690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3513d_level0_row6\" class=\"row_heading level0 row6\" >ada</th>\n",
       "      <td id=\"T_3513d_row6_col0\" class=\"data row6 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_3513d_row6_col1\" class=\"data row6 col1\" >0.6854</td>\n",
       "      <td id=\"T_3513d_row6_col2\" class=\"data row6 col2\" >0.6090</td>\n",
       "      <td id=\"T_3513d_row6_col3\" class=\"data row6 col3\" >0.6854</td>\n",
       "      <td id=\"T_3513d_row6_col4\" class=\"data row6 col4\" >0.6519</td>\n",
       "      <td id=\"T_3513d_row6_col5\" class=\"data row6 col5\" >0.5695</td>\n",
       "      <td id=\"T_3513d_row6_col6\" class=\"data row6 col6\" >0.0305</td>\n",
       "      <td id=\"T_3513d_row6_col7\" class=\"data row6 col7\" >0.0864</td>\n",
       "      <td id=\"T_3513d_row6_col8\" class=\"data row6 col8\" >2.4760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3513d_level0_row7\" class=\"row_heading level0 row7\" >et</th>\n",
       "      <td id=\"T_3513d_row7_col0\" class=\"data row7 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_3513d_row7_col1\" class=\"data row7 col1\" >0.6848</td>\n",
       "      <td id=\"T_3513d_row7_col2\" class=\"data row7 col2\" >0.6618</td>\n",
       "      <td id=\"T_3513d_row7_col3\" class=\"data row7 col3\" >0.6848</td>\n",
       "      <td id=\"T_3513d_row7_col4\" class=\"data row7 col4\" >0.6371</td>\n",
       "      <td id=\"T_3513d_row7_col5\" class=\"data row7 col5\" >0.6284</td>\n",
       "      <td id=\"T_3513d_row7_col6\" class=\"data row7 col6\" >0.1629</td>\n",
       "      <td id=\"T_3513d_row7_col7\" class=\"data row7 col7\" >0.1938</td>\n",
       "      <td id=\"T_3513d_row7_col8\" class=\"data row7 col8\" >10.4240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3513d_level0_row8\" class=\"row_heading level0 row8\" >dummy</th>\n",
       "      <td id=\"T_3513d_row8_col0\" class=\"data row8 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_3513d_row8_col1\" class=\"data row8 col1\" >0.6827</td>\n",
       "      <td id=\"T_3513d_row8_col2\" class=\"data row8 col2\" >0.5000</td>\n",
       "      <td id=\"T_3513d_row8_col3\" class=\"data row8 col3\" >0.6827</td>\n",
       "      <td id=\"T_3513d_row8_col4\" class=\"data row8 col4\" >0.4661</td>\n",
       "      <td id=\"T_3513d_row8_col5\" class=\"data row8 col5\" >0.5540</td>\n",
       "      <td id=\"T_3513d_row8_col6\" class=\"data row8 col6\" >0.0000</td>\n",
       "      <td id=\"T_3513d_row8_col7\" class=\"data row8 col7\" >0.0000</td>\n",
       "      <td id=\"T_3513d_row8_col8\" class=\"data row8 col8\" >0.0320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3513d_level0_row9\" class=\"row_heading level0 row9\" >knn</th>\n",
       "      <td id=\"T_3513d_row9_col0\" class=\"data row9 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_3513d_row9_col1\" class=\"data row9 col1\" >0.6407</td>\n",
       "      <td id=\"T_3513d_row9_col2\" class=\"data row9 col2\" >0.5858</td>\n",
       "      <td id=\"T_3513d_row9_col3\" class=\"data row9 col3\" >0.6407</td>\n",
       "      <td id=\"T_3513d_row9_col4\" class=\"data row9 col4\" >0.5806</td>\n",
       "      <td id=\"T_3513d_row9_col5\" class=\"data row9 col5\" >0.5939</td>\n",
       "      <td id=\"T_3513d_row9_col6\" class=\"data row9 col6\" >0.1053</td>\n",
       "      <td id=\"T_3513d_row9_col7\" class=\"data row9 col7\" >0.1150</td>\n",
       "      <td id=\"T_3513d_row9_col8\" class=\"data row9 col8\" >13.8770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3513d_level0_row10\" class=\"row_heading level0 row10\" >dt</th>\n",
       "      <td id=\"T_3513d_row10_col0\" class=\"data row10 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_3513d_row10_col1\" class=\"data row10 col1\" >0.5832</td>\n",
       "      <td id=\"T_3513d_row10_col2\" class=\"data row10 col2\" >0.5569</td>\n",
       "      <td id=\"T_3513d_row10_col3\" class=\"data row10 col3\" >0.5832</td>\n",
       "      <td id=\"T_3513d_row10_col4\" class=\"data row10 col4\" >0.5761</td>\n",
       "      <td id=\"T_3513d_row10_col5\" class=\"data row10 col5\" >0.5795</td>\n",
       "      <td id=\"T_3513d_row10_col6\" class=\"data row10 col6\" >0.1223</td>\n",
       "      <td id=\"T_3513d_row10_col7\" class=\"data row10 col7\" >0.1224</td>\n",
       "      <td id=\"T_3513d_row10_col8\" class=\"data row10 col8\" >1.3060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3513d_level0_row11\" class=\"row_heading level0 row11\" >qda</th>\n",
       "      <td id=\"T_3513d_row11_col0\" class=\"data row11 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_3513d_row11_col1\" class=\"data row11 col1\" >0.2278</td>\n",
       "      <td id=\"T_3513d_row11_col2\" class=\"data row11 col2\" >0.5028</td>\n",
       "      <td id=\"T_3513d_row11_col3\" class=\"data row11 col3\" >0.2278</td>\n",
       "      <td id=\"T_3513d_row11_col4\" class=\"data row11 col4\" >0.5752</td>\n",
       "      <td id=\"T_3513d_row11_col5\" class=\"data row11 col5\" >0.1151</td>\n",
       "      <td id=\"T_3513d_row11_col6\" class=\"data row11 col6\" >0.0055</td>\n",
       "      <td id=\"T_3513d_row11_col7\" class=\"data row11 col7\" >0.0322</td>\n",
       "      <td id=\"T_3513d_row11_col8\" class=\"data row11 col8\" >3.2640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3513d_level0_row12\" class=\"row_heading level0 row12\" >nb</th>\n",
       "      <td id=\"T_3513d_row12_col0\" class=\"data row12 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_3513d_row12_col1\" class=\"data row12 col1\" >0.1983</td>\n",
       "      <td id=\"T_3513d_row12_col2\" class=\"data row12 col2\" >0.5723</td>\n",
       "      <td id=\"T_3513d_row12_col3\" class=\"data row12 col3\" >0.1983</td>\n",
       "      <td id=\"T_3513d_row12_col4\" class=\"data row12 col4\" >0.5902</td>\n",
       "      <td id=\"T_3513d_row12_col5\" class=\"data row12 col5\" >0.1142</td>\n",
       "      <td id=\"T_3513d_row12_col6\" class=\"data row12 col6\" >0.0458</td>\n",
       "      <td id=\"T_3513d_row12_col7\" class=\"data row12 col7\" >0.0954</td>\n",
       "      <td id=\"T_3513d_row12_col8\" class=\"data row12 col8\" >0.6210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x291a78d00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n",
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n",
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n",
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n",
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n",
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n",
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n",
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n",
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n",
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n",
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n",
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n",
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n",
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n",
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n",
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n",
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n",
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n",
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n",
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n"
     ]
    }
   ],
   "source": [
    "best_model = compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_8f4bd\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8f4bd_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_8f4bd_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_8f4bd_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_8f4bd_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_8f4bd_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_8f4bd_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_8f4bd_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8f4bd_level0_row0\" class=\"row_heading level0 row0\" >Test</th>\n",
       "      <td id=\"T_8f4bd_row0_col0\" class=\"data row0 col0\" >0.6988</td>\n",
       "      <td id=\"T_8f4bd_row0_col1\" class=\"data row0 col1\" >0.6784</td>\n",
       "      <td id=\"T_8f4bd_row0_col2\" class=\"data row0 col2\" >0.6988</td>\n",
       "      <td id=\"T_8f4bd_row0_col3\" class=\"data row0 col3\" >0.6519</td>\n",
       "      <td id=\"T_8f4bd_row0_col4\" class=\"data row0 col4\" >0.6261</td>\n",
       "      <td id=\"T_8f4bd_row0_col5\" class=\"data row0 col5\" >0.1541</td>\n",
       "      <td id=\"T_8f4bd_row0_col6\" class=\"data row0 col6\" >0.2057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2b0c19600>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = create_model('lr', cross_validation=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 2.0073\n",
      "Epoch [20/100], Loss: 1.8807\n",
      "Epoch [30/100], Loss: 1.7599\n",
      "Epoch [40/100], Loss: 1.6436\n",
      "Epoch [50/100], Loss: 1.5312\n",
      "Epoch [60/100], Loss: 1.4224\n",
      "Epoch [70/100], Loss: 1.3169\n",
      "Epoch [80/100], Loss: 1.2148\n",
      "Epoch [90/100], Loss: 1.1166\n",
      "Epoch [100/100], Loss: 1.0236\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>#small</th>\n",
       "      <th>#true2size</th>\n",
       "      <th>#large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>result</th>\n",
       "      <td>0.686851</td>\n",
       "      <td>0.22895</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.271453</td>\n",
       "      <td>0.559343</td>\n",
       "      <td>0</td>\n",
       "      <td>11940</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy  precision    recall        f1  f1_weighted  #small  \\\n",
       "result  0.686851    0.22895  0.333333  0.271453     0.559343       0   \n",
       "\n",
       "        #true2size  #large  \n",
       "result       11940       0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "input_dim = train_df_prep.drop('fit', axis=1).shape[1]\n",
    "output_dim = 3\n",
    "inputs = torch.tensor(train_df_prep.drop('fit', axis=1).values,\n",
    "                      dtype=torch.float32)\n",
    "labels = torch.tensor(train_df_prep['fit'].values, dtype=torch.long)\n",
    "\n",
    "\n",
    "# Define the model\n",
    "class LogisticRegression(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "num_epochs = 100\n",
    "learning_rate = 0.01\n",
    "lamda = 1\n",
    "\n",
    "# Define the loss function and the optimizer\n",
    "model = LogisticRegression(input_dim, output_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels) + lamda * torch.norm(model.linear.weight)\n",
    "\n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Test the model\n",
    "with torch.no_grad():\n",
    "    predicted = model(\n",
    "        torch.tensor(test_df_prep.drop('fit', axis=1).values,\n",
    "                     dtype=torch.float32))\n",
    "    _, predicted = torch.max(predicted.data, 1)\n",
    "    y_pred = predicted.numpy()\n",
    "\n",
    "evaluate_model(test_df_prep['fit'], y_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d25da615e19396787fe4ca1ac6e145a6d087d3a93322fbf7b59c4188e44aa5c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
